{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thv-nsYeRmKd",
        "outputId": "019984ae-cdf1-47af-bd70-4893d07fd3b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n",
            "Collecting ekphrasis\n",
            "  Downloading ekphrasis-0.5.4-py3-none-any.whl.metadata (610 bytes)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ekphrasis) (2.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ekphrasis) (4.67.1)\n",
            "Collecting colorama (from ekphrasis)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting ujson (from ekphrasis)\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from ekphrasis) (3.10.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from ekphrasis) (3.9.1)\n",
            "Collecting ftfy (from ekphrasis)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ekphrasis) (1.26.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->ekphrasis) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->ekphrasis) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->ekphrasis) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->ekphrasis) (2024.11.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->ekphrasis) (1.17.0)\n",
            "Downloading ekphrasis-0.5.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ujson, ftfy, colorama, ekphrasis\n",
            "Successfully installed colorama-0.4.6 ekphrasis-0.5.4 ftfy-6.3.1 ujson-5.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji\n",
        "!pip install ekphrasis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGE_i2kcSKdp",
        "outputId": "7d67cf48-2538-4b44-e77e-dd2959433438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plotly==4.5.4\n",
            "  Downloading plotly-4.5.4-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting retrying>=1.3.3 (from plotly==4.5.4)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from plotly==4.5.4) (1.17.0)\n",
            "Downloading plotly-4.5.4-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: retrying, plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n"
          ]
        }
      ],
      "source": [
        "pip install plotly==4.5.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9V9T_tySNdv"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.2.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ekphrasis"
      ],
      "metadata": {
        "id": "vJeSiVgonnG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "id": "zjL7h6j4oI0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhYj3id7STR3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import os\n",
        "\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On6Kym7GScoz"
      },
      "outputs": [],
      "source": [
        "text_processor = TextPreProcessor(\n",
        "    # terms that will be normalized\n",
        "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "        'time', 'url', 'date', 'number'],\n",
        "    # terms that will be annotated\n",
        "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "        'emphasis', 'censored'},\n",
        "    fix_html=True,  # fix HTML tokens\n",
        "\n",
        "    # corpus from which the word statistics are going to be used\n",
        "    # for word segmentation\n",
        "    segmenter=\"twitter\",\n",
        "\n",
        "    # corpus from which the word statistics are going to be used\n",
        "    # for spell correction\n",
        "    corrector=\"twitter\",\n",
        "\n",
        "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
        "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
        "    spell_correct_elong=True,  # spell correction for elongated words\n",
        "\n",
        "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
        "    # the tokenizer, should take as input a string and return a list of tokens\n",
        "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "\n",
        "    # list of dictionaries, for replacing tokens extracted from the text,\n",
        "    # with other expressions. You can pass more than one dictionaries.\n",
        "    dicts=[emoticons]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2j-gZk5XUzi"
      },
      "outputs": [],
      "source": [
        "def print_text(texts,i,j):\n",
        "    for u in range(i,j):\n",
        "        print(texts[u])\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v80ry0zES5-Q"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/train.csv',delimiter=',',encoding='utf-8')  # train set\n",
        "print(list(df.columns.values)) #file header"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU1Dl23ZW_qg"
      },
      "outputs": [],
      "source": [
        "text_array = df[\"text\"]\n",
        "labels = df[\"label_sexist\"]\n",
        "original = text_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiESD9alUVv_"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz7CAmS43DT7"
      },
      "outputs": [],
      "source": [
        "df_validate = pd.read_csv('/content/validate.csv',delimiter=',',encoding='utf-8') # validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PiJ-J_cLNRs"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('/content/test.csv',delimiter=',',encoding='utf-8') # test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i39zHOkrAA5S"
      },
      "outputs": [],
      "source": [
        "#check if need to change\n",
        "text_array_val = df_validate[\"text\"]\n",
        "labels_val = df_validate[\"label_sexist\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj28ibULc0VJ"
      },
      "outputs": [],
      "source": [
        "len(labels_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYtZdKvWS8c4"
      },
      "outputs": [],
      "source": [
        "test_set_text = df_test[\"text\"]\n",
        "labels_test_set = df_test[\"label_sexist\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNK6vTYLLvOC"
      },
      "outputs": [],
      "source": [
        "#removing website names\n",
        "def remove_website(text):\n",
        "    return \" \".join([word if re.search(\"r'https?://\\S+|www\\.\\S+'|((?i).com$|.co|.net)\",word)==None else \"\" for word in text.split(\" \") ])\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: remove_website(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: remove_website(text))\n",
        "print_text(text_array_val,0,10)\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Test set\n",
        "test_set_text = test_set_text.apply(lambda text: remove_website(text))\n",
        "print_text(test_set_text,0,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTyKWFSp05HG"
      },
      "outputs": [],
      "source": [
        "# Functions for chat word conversion\n",
        "f = open(\"/content/slang.txt\", \"r\")\n",
        "chat_words_str = f.read()\n",
        "chat_words_map_dict = {}\n",
        "chat_words_list = []\n",
        "\n",
        "for line in chat_words_str.split(\"\\n\"):\n",
        "    if line != \"\":\n",
        "        cw = line.split(\"=\")[0]\n",
        "        cw_expanded = line.split(\"=\")[1]\n",
        "        chat_words_list.append(cw)\n",
        "        chat_words_map_dict[cw] = cw_expanded\n",
        "chat_words_list = set(chat_words_list)\n",
        "\n",
        "def chat_words_conversion(text):\n",
        "    new_text = []\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_words_list:\n",
        "            new_text.append(chat_words_map_dict[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfe93aAS06Wc"
      },
      "outputs": [],
      "source": [
        "# Chat word conversion\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(text_array,0,10)\n",
        "print_text(original,0,10)\n",
        "\n",
        "print(\"********************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(text_array_val,0,10)\n",
        "\n",
        "print(\"********************************************************************************\")\n",
        "\n",
        "# Test set\n",
        "test_set_text = test_set_text.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(test_set_text,0,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbo9MAkIMoeD"
      },
      "outputs": [],
      "source": [
        "#check code in other copy\n",
        "import re\n",
        "\n",
        "# Define a dictionary of emoticons and their corresponding meanings\n",
        "EMOTICONS = {\n",
        "    ':)': 'smile',\n",
        "    ':-)': 'smile',\n",
        "    ':(': 'sad',\n",
        "    ':-(': 'sad',\n",
        "    ':D': 'laugh',\n",
        "    '<3': 'love'\n",
        "}\n",
        "\n",
        "def convert_emoticons(text):\n",
        "    # Iterate over each emoticon in the dictionary\n",
        "    for emot, meaning in EMOTICONS.items():\n",
        "        # Replace the emoticon with its corresponding meaning in the text\n",
        "        text = re.sub(r'(?i)' + re.escape(emot), meaning, text)\n",
        "    return text\n",
        "\n",
        "# Test the emoticon conversion function\n",
        "text = \"Hello :-) :-(\"\n",
        "text = convert_emoticons(text)\n",
        "print(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhZ_DoR3MpKS"
      },
      "outputs": [],
      "source": [
        "# Emoticon conversion\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: convert_emoticons(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**********************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: convert_emoticons(text))\n",
        "print_text(text_array_val,0,10)\n",
        "\n",
        "print(\"**********************************************************************************\")\n",
        "\n",
        "# Test set\n",
        "test_set_text = test_set_text.apply(lambda text: convert_emoticons(text))\n",
        "print_text(test_set_text,0,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM1yQA57MrqJ"
      },
      "outputs": [],
      "source": [
        "# FUnction for removal of emoji\n",
        "import emoji\n",
        "\n",
        "def convert_emojis(text):\n",
        "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "    text = re.sub(\"_|-\",\" \",text)\n",
        "    return text\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: convert_emojis(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: convert_emojis(text))\n",
        "print_text(text_array_val,0,10)\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Test set\n",
        "test_set_text = test_set_text.apply(lambda text: convert_emojis(text))\n",
        "print_text(test_set_text,0,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpXkILXVkI2e"
      },
      "outputs": [],
      "source": [
        "# Ekphrasis pipe for text pre-processing\n",
        "def ekphrasis_pipe(sentence):\n",
        "    cleaned_sentence = \" \".join(text_processor.pre_process_doc(sentence))\n",
        "    return cleaned_sentence\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Training set completed.......\")\n",
        "#Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Validation set completed.......\")\n",
        "#Test set\n",
        "test_set_text = test_set_text.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Test set completed.......\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBMPzUCGMxi8"
      },
      "outputs": [],
      "source": [
        "# Removing unnecessary punctuations\n",
        "PUNCT_TO_REMOVE = \"\\\"$%&'()+,-./;=[\\]^_`{|}~\"\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: remove_punctuation(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"********************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: remove_punctuation(text))\n",
        "print_text(text_array_val,0,10)\n",
        "\n",
        "print(\"********************************************************************\")\n",
        "\n",
        "# Test set\n",
        "test_set_text = test_set_text.apply(lambda text: remove_punctuation(text))\n",
        "print_text(test_set_text,0,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwoKCYYyM4uE"
      },
      "source": [
        "Text pre-processing complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0-VAgWD2DiM"
      },
      "outputs": [],
      "source": [
        "# Count of each label in dataset\n",
        "from collections import Counter\n",
        "\n",
        "# Printing training set counts for analysis\n",
        "print(\"Elements: \",set(labels))\n",
        "print(\"Length: \",len(labels))\n",
        "print(Counter(labels))\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Printing validation set counts for analysis\n",
        "print(\"Elements: \",set(labels_val))\n",
        "print(\"Length: \",len(labels_val))\n",
        "print(Counter(labels_val))\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Printing Test set counts for analysis\n",
        "print(\"Elements: \",set(labels_test_set))\n",
        "print(\"Length: \",len(labels_test_set))\n",
        "print(Counter(labels_test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDAcapdfIEY2"
      },
      "outputs": [],
      "source": [
        "Y = []\n",
        "Y_vali = []\n",
        "Y_test_set = []\n",
        "\n",
        "# Training set\n",
        "for i in range(0,len(labels)):\n",
        "    if(labels[i] == \"sexist\"):\n",
        "        Y.append(0)\n",
        "    if(labels[i] == \"not sexist\"):\n",
        "        Y.append(1)\n",
        "\n",
        "# Validation set\n",
        "for i in range(0,len(labels_val)):\n",
        "    if(labels_val[i] == \"sexist\"):\n",
        "        Y_vali.append(0)\n",
        "    if(labels_val[i] == \"not sexist\"):\n",
        "        Y_vali.append(1)\n",
        "\n",
        "# Test set\n",
        "for i in range(0,len(labels_test_set)):\n",
        "    if(labels_test_set[i] == \"sexist\"):\n",
        "        Y_test_set.append(0)\n",
        "    if(labels_test_set[i] == \"not sexist\"):\n",
        "        Y_test_set.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N0FQM7BdD5w"
      },
      "outputs": [],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB02S2kcdGpt"
      },
      "outputs": [],
      "source": [
        "len(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edw6lzxnc9_I"
      },
      "outputs": [],
      "source": [
        "len(labels_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEcRDdNYc5pS"
      },
      "outputs": [],
      "source": [
        "len(Y_vali)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Whi_nRl9ek4"
      },
      "outputs": [],
      "source": [
        "# Verifying train set\n",
        "X = np.asarray(list(text_array))\n",
        "Y = np.asarray(list(Y))\n",
        "print(type(X))\n",
        "print(type(Y))\n",
        "print(np.shape(X),np.shape(Y))\n",
        "\n",
        "# Verifying validation set\n",
        "X_val = np.asarray(list(text_array_val))\n",
        "Y_vali = np.asarray(list(Y_vali))\n",
        "print(type(X_val))\n",
        "print(type(Y_vali))\n",
        "print(np.shape(X_val),np.shape(Y_vali))\n",
        "\n",
        "# Verifying test set\n",
        "X_test_set = np.asarray(list(test_set_text))\n",
        "Y_test_set = np.asarray(list(Y_test_set))\n",
        "print(type(X_test_set))\n",
        "print(type(Y_test_set))\n",
        "print(np.shape(X_test_set),np.shape(Y_test_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28bwIHkyQ7RF"
      },
      "source": [
        "Shuffling training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1w_vEvpDbAi"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h67EtBY9EKA3"
      },
      "outputs": [],
      "source": [
        "# Converting to one hot vectors\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)] #u[Y] helps to index each element of Y index at u. U here is a class array\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7O6QDckQ_E0"
      },
      "outputs": [],
      "source": [
        "Y_oh_train = convert_to_one_hot(np.array(Y), C = 2)\n",
        "Y_oh_val = convert_to_one_hot(np.array(Y_vali), C = 2)\n",
        "Y_oh_test_set = convert_to_one_hot(np.array(Y_test_set), C = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmJu8nJgRHiG"
      },
      "source": [
        "Model using RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xikBSaUiEbNO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import os\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6z0nB1-Eczs"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "from transformers import RobertaTokenizerFast, TFRobertaModel, TFBertModel, BertTokenizerFast, ElectraTokenizerFast, TFElectraModel, AlbertTokenizerFast, TFAlbertModel, XLNetTokenizerFast, TFXLNetModel, MPNetTokenizerFast, TFMPNetModel\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import RepeatVector, Concatenate, Dense, Activation, Dot, BatchNormalization, Dropout\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPzZenz7Eiy-"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRhK9zHA4szW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if a GPU is available\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    print(\"GPU is not available\")\n",
        "\n",
        "# List available GPU devices\n",
        "print(\"All devices: \", tf.config.list_logical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfaniYX23roK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check if TPU address environment variable is set\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "else:\n",
        "    print(\"TPU not found. Please ensure that TPU is enabled in your runtime settings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    print(\"TPU initialized.\")\n",
        "    print(\"TPU type: \", resolver.cluster_spec().as_dict())\n",
        "else:\n",
        "    print(\"TPU not found. Please ensure that TPU is enabled in your runtime settings.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "r1tH5jI9pVaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L--7fVVGEo1R"
      },
      "outputs": [],
      "source": [
        "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "#\n",
        "# tf.config.experimental_connect_to_cluster(resolver)\n",
        "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "# print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvJRZyvJEuO5"
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awmJ8OnsEw0y"
      },
      "outputs": [],
      "source": [
        "X = list(X)\n",
        "X_val = list(X_val)\n",
        "X_test_set = list(X_test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrB7g2nuOJaM"
      },
      "outputs": [],
      "source": [
        "len(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMkO1e1gOLZz"
      },
      "outputs": [],
      "source": [
        "len(Y_vali)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G65y4RqdE078"
      },
      "outputs": [],
      "source": [
        "model_train_x, model_val_x, Y_train, Y_val = train_test_split(X, Y, test_size=0.05, random_state=44)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8YwPp8zE22R"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(model_train_x, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')\n",
        "val_encodings = tokenizer(model_val_x, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')\n",
        "test_encodings = tokenizer(X_val, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdI8gDW2E5Cm"
      },
      "outputs": [],
      "source": [
        "cluster_encodings = tokenizer(X, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgK1aFOjROzM"
      },
      "source": [
        "Subtask A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kic8iUpwq-4W"
      },
      "outputs": [],
      "source": [
        "def Offense_classifier(input_shape):\n",
        "    \"\"\"\n",
        "    Function creating the model's graph.\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the input,(max_len,)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 100-dimensional vector representation\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (13 million words)\n",
        "\n",
        "    Returns:\n",
        "    model -- a model instance in Keras\n",
        "    \"\"\"\n",
        "    model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "    layer = model.layers[0]\n",
        "\n",
        "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
        "    inputs = keras.Input(shape=input_shape, dtype='int32')\n",
        "    input_masks = keras.Input(shape=input_shape, dtype='int32')\n",
        "\n",
        "    embeddings = layer([inputs, input_masks])[1]\n",
        "\n",
        "    X = BatchNormalization(momentum=0.99, epsilon=0.001, center=True, scale=True)(embeddings)\n",
        "\n",
        "    # Add dropout with a probability of 0.1\n",
        "    X = Dropout(0.1)(X)\n",
        "\n",
        "    X = Dense(128,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = Dense(32,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = Dense(3,activation='elu',kernel_regularizer=keras.regularizers.l2(0.01))(X)\n",
        "\n",
        "    X = Dense(32,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = BatchNormalization(momentum=0.99, epsilon=0.001, center=True, scale=True)(X)\n",
        "\n",
        "    X = Dense(128,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = Dense(1,activation='linear',kernel_regularizer=keras.regularizers.l2(0.01))(X)\n",
        "\n",
        "    # Add a sigmoid activation\n",
        "    X = Activation('sigmoid')(X)\n",
        "\n",
        "    # Create Model instance which converts sentence_indices into X.\n",
        "    model = keras.Model(inputs=[inputs,input_masks], outputs=[X])\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDuF4nQD-Sne"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q9_WbRTrEXX"
      },
      "outputs": [],
      "source": [
        "# strategy = tf.distribute.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKpq5QOnrHPO"
      },
      "outputs": [],
      "source": [
        "class EvaluationMetric(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, trial_encodings, trial_masks, Y_vali):\n",
        "        super(EvaluationMetric, self).__init__()\n",
        "        self.trial_encodings = trial_encodings\n",
        "        self.trial_masks = trial_masks\n",
        "        self.Y_vali = Y_vali\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        print(\"\\nTraining...\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        print(\"\\nEvaluating...\")\n",
        "        trial_prediction = self.model.predict([self.trial_encodings,self.trial_masks])\n",
        "\n",
        "        pred = []\n",
        "        for i in range(0,len(self.Y_vali)):\n",
        "            num = trial_prediction[i]\n",
        "            if(num > 0.5):\n",
        "              num = 1\n",
        "            else:\n",
        "              num = 0\n",
        "            pred.append(num)\n",
        "\n",
        "        from sklearn.metrics import classification_report\n",
        "        print(classification_report(Y_vali, pred, digits=3))\n",
        "\n",
        "evaluation_metric = EvaluationMetric(test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"], Y_vali)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "id": "Sv9Q1Wf3rgAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFRobertaModel\n",
        "\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\", from_pt=True)\n",
        "# \"from_pt=True\" converts a PyTorch model to TensorFlow.\n"
      ],
      "metadata": {
        "id": "vpgCJtqTsM1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR4quxDRrJyj"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    model = Offense_classifier((100,))\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=2e-5)\n",
        "    loss_fun = [\n",
        "          tf.keras.losses.BinaryCrossentropy()\n",
        "    ]\n",
        "    metric = ['acc']\n",
        "    model.compile(optimizer=optimizer, loss=loss_fun, metrics=metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbw9f7nKrgik"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLPkHQQ6GZyQ"
      },
      "outputs": [],
      "source": [
        "neg, pos = np.bincount(Y)\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ztpv2yAdGdv6"
      },
      "outputs": [],
      "source": [
        "class_weight = {}\n",
        "maxi = max(neg, pos)\n",
        "weight_for_0 = (maxi / (maxi + neg))\n",
        "weight_for_1 = (maxi / (maxi + pos))\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UprEFatGhiz"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Colab Notebooks/olid_roberta.006 (1).h5',\n",
        "                                 monitor='val_acc',\n",
        "                                 verbose=1,\n",
        "                                 save_weights_only=True,\n",
        "                                 period=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G83ONMQMnot"
      },
      "outputs": [],
      "source": [
        "len(train_encodings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np2CrysnNe2B"
      },
      "outputs": [],
      "source": [
        "len(model_val_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwTCMOnnMz4u"
      },
      "outputs": [],
      "source": [
        "len(Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBqqK_XtGsyV"
      },
      "outputs": [],
      "source": [
        "# val 0.05\n",
        "history = model.fit(\n",
        "    x = [train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"]],\n",
        "    y = Y_train,\n",
        "    validation_data = ([val_encodings[\"input_ids\"],val_encodings[\"attention_mask\"]],Y_val),\n",
        "    callbacks = [evaluation_metric, checkpoint],\n",
        "    batch_size = 64,\n",
        "    shuffle=True,\n",
        "    epochs=6,\n",
        "    class_weight = class_weight\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4YBWcqjI5_W"
      },
      "outputs": [],
      "source": [
        "history = history\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdayDULpd3os"
      },
      "outputs": [],
      "source": [
        "test_set_encodings = tokenizer(X_test_set, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mDZe7OWJKzQ"
      },
      "outputs": [],
      "source": [
        "answer = model.predict([test_set_encodings[\"input_ids\"], test_set_encodings[\"attention_mask\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27X_bvqXJO5l"
      },
      "outputs": [],
      "source": [
        "pred = []\n",
        "for i in range(0,len(X_test_set)):\n",
        "\n",
        "    num = answer[i]\n",
        "    if(num >= 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred.append(num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGeqKSd4JQPu"
      },
      "outputs": [],
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_test_set, predictions=pred)\n",
        "print(con_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyJR1m1SJTxe"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfm9DCQ_JVnx"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.set(font_scale=1.75)\n",
        "sns.heatmap(con_mat, annot=True,cmap=plt.cm.viridis,fmt='d', xticklabels=[\"Sexist\",\"Not Sexist\"], yticklabels=[\"Sexist\",\"Not Sexist\"],annot_kws={\"size\": 15})\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PxybItPJYpy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKoW1Np7Jaal"
      },
      "outputs": [],
      "source": [
        "f1_score(Y_test_set, pred, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWAz6lcHJc6F"
      },
      "outputs": [],
      "source": [
        "print(classification_report(Y_test_set, pred, target_names=[\"sexist\", \"not sexist\"], digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5OGZxqbJhGY"
      },
      "outputs": [],
      "source": [
        "answer_train = model.predict([cluster_encodings[\"input_ids\"], cluster_encodings[\"attention_mask\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnQ7qsQMKkpa"
      },
      "outputs": [],
      "source": [
        "answer_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9S6nkmkOMXg"
      },
      "source": [
        "Train set analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU8RXKoeJjHd"
      },
      "outputs": [],
      "source": [
        "pred = []\n",
        "sample = original\n",
        "count = 0\n",
        "for i in range(0,len(Y)):\n",
        "\n",
        "    num = answer_train[i]         # num\n",
        "    lol = num                     # lol = 0.8\n",
        "    if(num > 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred.append(num)\n",
        "    if(num != Y[i] and Y[i] == 0 and lol >=0.8):\n",
        "        print(answer_train[i])\n",
        "        print(\"Original label: \",labels[i])\n",
        "        print(\"Without pre-processing: \",sample[i])\n",
        "        print(\"With pre-processing: \",X[i])\n",
        "        lol = \"\"\n",
        "        count += 1\n",
        "\n",
        "        if(num == 0):\n",
        "            lol = \"Sexist\"\n",
        "        if(num == 1):\n",
        "            lol = \"Not Sexist\"\n",
        "        print(\"Predicted: \" + lol)\n",
        "        print()\n",
        "\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI6ChFeKOF5v"
      },
      "source": [
        "Training explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "395PCaRFKzGy"
      },
      "outputs": [],
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-eL3anCNTgR"
      },
      "outputs": [],
      "source": [
        "# 3 neuron output\n",
        "model.layers[-6].name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pyMc8lhNaCX"
      },
      "outputs": [],
      "source": [
        "cluster_dense_3 = keras.Model(inputs=model.input, outputs=model.layers[-6].output)\n",
        "with strategy.scope():\n",
        "    cluster_3 = cluster_dense_3.predict([cluster_encodings[\"input_ids\"], cluster_encodings[\"attention_mask\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G91XmYYCNrmX"
      },
      "outputs": [],
      "source": [
        "pred_train = []\n",
        "temp = 0\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "\n",
        "    num = answer_train[i]\n",
        "\n",
        "    if(num >= 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred_train.append(num)\n",
        "\n",
        "print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvEsLW32N9QC"
      },
      "outputs": [],
      "source": [
        "#\n",
        "\n",
        "flag = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "    count = count + 1\n",
        "    x_.append(cluster_3[i][1])\n",
        "    y_.append(cluster_3[i][0])\n",
        "    z_.append(cluster_3[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdsx29U1OAgx"
      },
      "outputs": [],
      "source": [
        "Counter(flag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv9MSUH3OUGX"
      },
      "outputs": [],
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y, predictions=pred_train)\n",
        "print(con_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsM7h5NvOYFM"
      },
      "outputs": [],
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(flag)):\n",
        "    if flag[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if flag[i] == 1:\n",
        "      pred_colour.append(\"Not sexist\")\n",
        "    if flag[i] == 0:\n",
        "      pred_colour.append(\"Sexist\")\n",
        "\n",
        "test_df = pd.DataFrame({'x':x_, 'y':y_, 'z':z_, 'Labels':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='x', y='y', z='z', color='Labels')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 0.7,\n",
        "        'colorscale' : 'Oryel',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 750, height = 500)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwTAJ5wAOjzj"
      },
      "outputs": [],
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(flag)):\n",
        "    if pred_train[i] == 1:\n",
        "      pred_colour.append(\"Not Sexist\")\n",
        "    if pred_train[i] == 0:\n",
        "      pred_colour.append(\"Sexist\")\n",
        "\n",
        "test_df = pd.DataFrame({'X':x_, 'Y':y_, 'Z':z_, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='X', y='Y', z='Z', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'rainbow',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIF_kSiIO_ce"
      },
      "source": [
        "Traning examination end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNC2aW02PJ8k"
      },
      "source": [
        "CLUSTERING\n",
        "RoBERTa PLM layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l17XLkZGPJQ0"
      },
      "outputs": [],
      "source": [
        "model.layers[-8].name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0Aildm7O7n0"
      },
      "outputs": [],
      "source": [
        "cluster_bert = keras.Model(inputs=model.input, outputs=model.layers[-8].output)\n",
        "with strategy.scope():\n",
        "    cl_bert = cluster_bert.predict([cluster_encodings[\"input_ids\"], cluster_encodings[\"attention_mask\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6cSz1JuQF04"
      },
      "outputs": [],
      "source": [
        "len(cl_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MYQICtfQK0q"
      },
      "outputs": [],
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "    count = count + 1\n",
        "    x_bert.append(cl_bert[i][0])\n",
        "    y_bert.append(cl_bert[i][1])\n",
        "    z_bert.append(cl_bert[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_bert.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8m2uwz3QRcU"
      },
      "source": [
        "k-means PLM layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFf8pvMmQMr1"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p9YtXtqQX59"
      },
      "outputs": [],
      "source": [
        "kmeans_bert = KMeans(n_clusters=3, random_state=44).fit(cl_bert)\n",
        "y_kmeans_bert = kmeans_bert.predict(cl_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux0NHafpQZ-b"
      },
      "outputs": [],
      "source": [
        "Counter(y_kmeans_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASG8JgxFQbwF"
      },
      "outputs": [],
      "source": [
        "Counter(flag_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VPl-vNIQeDL"
      },
      "outputs": [],
      "source": [
        "# 1 index values are sexist\n",
        "# 0 index values are not sexist\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_bert)):\n",
        "      if flag_bert[i] == 2 and y_kmeans_bert[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHF-GmgKQtjP"
      },
      "outputs": [],
      "source": [
        "for i in range(0,len(flag_bert)):\n",
        "    if(y_kmeans_bert[i] == 0):\n",
        "      y_kmeans_bert[i] = 1\n",
        "    elif(y_kmeans_bert[i] == 1):\n",
        "      y_kmeans_bert[i] = 0\n",
        "    else:\n",
        "      y_kmeans_bert[i] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2jkQvB2Q01Y"
      },
      "outputs": [],
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "    count = count + 1\n",
        "    x_bert.append(cl_bert[i][0])\n",
        "    y_bert.append(cl_bert[i][1])\n",
        "    z_bert.append(cl_bert[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_bert.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svDN-MlYQ28a"
      },
      "outputs": [],
      "source": [
        "Counter(flag_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujkU0M07Q61C"
      },
      "outputs": [],
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_bert, predictions=y_kmeans_bert)\n",
        "print(con_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RchEjyG0Q76l"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_bert, y_kmeans_bert, output_dict=False, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwkLYV3ARBi_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9vto-mwRDlQ"
      },
      "outputs": [],
      "source": [
        "centers_bert = kmeans_bert.cluster_centers_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6HeeNMeeXsM"
      },
      "source": [
        "Cosine Similarity Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBJ-5_AlRF1n"
      },
      "outputs": [],
      "source": [
        "svns_off = []\n",
        "for i in range(0,len(Y)):\n",
        "    off = cosine(cl_bert[i], centers_bert[1])/2\n",
        "    svns_off.append(1-off)\n",
        "print(len(svns_off))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2RIv5_ERHpz"
      },
      "outputs": [],
      "source": [
        "svns_noff = []\n",
        "for i in range(0,len(Y)):\n",
        "    noff = cosine(cl_bert[i], centers_bert[0])/2\n",
        "    svns_noff.append(1-noff)\n",
        "print(len(svns_noff))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo0VAvVzRHoC"
      },
      "outputs": [],
      "source": [
        "svns_neu = []\n",
        "for i in range(0,len(Y)):\n",
        "    neu = cosine(cl_bert[i], centers_bert[2])/2\n",
        "    svns_neu.append(1-neu)\n",
        "print(len(svns_neu))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS7UV_7TRORW"
      },
      "source": [
        "k-means PLM plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNUehChERP9M"
      },
      "outputs": [],
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VDaPyjSRRyb"
      },
      "outputs": [],
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(Y)):\n",
        "    if y_kmeans_bert[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_bert[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_bert[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':svns_off, 'SVNS Not Offensive':svns_noff, 'SVNS Neutral':svns_neu, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    },\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZU3trXnWH_C"
      },
      "outputs": [],
      "source": [
        "print(\"Length of svns_off:\", len(svns_off))\n",
        "print(\"Length of svns_neu:\", len(svns_neu))\n",
        "print(\"Length of svns_noff:\", len(svns_noff))\n",
        "print(len(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWcmgbKpib6E"
      },
      "outputs": [],
      "source": [
        "num=len(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvDC79b1RVLW"
      },
      "outputs": [],
      "source": [
        "pred_krobert = []\n",
        "# Assuming svns_off, svns_neu, and svns_noff are arrays or lists\n",
        "for i in range(num):\n",
        "    if(svns_off[i] > svns_neu[i]+svns_noff[i]):\n",
        "      pred_krobert.append(0)\n",
        "    elif (svns_noff[i] > svns_neu[i] and svns_noff[i] > svns_off[i]):\n",
        "      pred_krobert.append(1)\n",
        "    elif (svns_neu[i]>svns_noff[i] and svns_neu[i]>svns_off[i]):\n",
        "      pred_krobert.append(1)\n",
        "    else:\n",
        "      pred_krobert.append(0)\n",
        "print(classification_report(Y, pred_krobert, output_dict=False, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-QFCOTijNNv"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming svns_off, svns_neu, and svns_noff are arrays or lists\n",
        "X = list(zip(svns_off, svns_neu, svns_noff))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Train the decision tree model\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "\n",
        "# Predict using the trained model\n",
        "pred_krobert = decision_tree.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(Y_test, pred_krobert, digits=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJAEH4_UQXRw"
      },
      "source": [
        "Test Explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXQxKYdVQa5g"
      },
      "outputs": [],
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcnmXieJQgkR"
      },
      "outputs": [],
      "source": [
        "# 3 neuron output\n",
        "model.layers[-6].name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWX0WrU1QkEa"
      },
      "outputs": [],
      "source": [
        "cluster_dense_3 = keras.Model(inputs=model.input, outputs=model.layers[-6].output)\n",
        "with strategy.scope():\n",
        "    test_3 = cluster_dense_3.predict([test_set_encodings[\"input_ids\"], test_set_encodings[\"attention_mask\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7fqXkjItaqI"
      },
      "outputs": [],
      "source": [
        "pred_train = []\n",
        "temp = 0\n",
        "\n",
        "for i in range(0,len(Y_test_set)):\n",
        "\n",
        "    num = answer[i]\n",
        "\n",
        "    if(num >= 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred_train.append(num)\n",
        "\n",
        "print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDVbxkOetdtH"
      },
      "outputs": [],
      "source": [
        "#\n",
        "\n",
        "flag = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y_test_set)):\n",
        "    count = count + 1\n",
        "    x_.append(test_3[i][1])\n",
        "    y_.append(test_3[i][0])\n",
        "    z_.append(test_3[i][2])\n",
        "\n",
        "    if( answer[i] > 0.3 and answer[i] < 0.7 ):\n",
        "        flag.append(2)\n",
        "\n",
        "    if( answer[i] > 0 and answer[i] <= 0.3 ):\n",
        "        flag.append(0)\n",
        "\n",
        "    if( answer[i] >= 0.7 and answer[i] < 1 ):\n",
        "        flag.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hoza_rc2tiEb"
      },
      "outputs": [],
      "source": [
        "Counter(flag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GrRmdyhvK6B"
      },
      "outputs": [],
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_test_set, predictions=pred_train)\n",
        "print(con_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFJgdl9Fvv61"
      },
      "outputs": [],
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(flag)):\n",
        "    if flag[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if flag[i] == 1:\n",
        "      pred_colour.append(\"Not sexist\")\n",
        "    if flag[i] == 0:\n",
        "      pred_colour.append(\"Sexist\")\n",
        "\n",
        "test_df = pd.DataFrame({'x':x_, 'y':y_, 'z':z_, 'Labels':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='x', y='y', z='z', color='Labels')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 0.7,\n",
        "        'colorscale' : 'Oryel',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 750, height = 500)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEuev3B-v5uv"
      },
      "outputs": [],
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(flag)):\n",
        "    if pred_train[i] == 1:\n",
        "      pred_colour.append(\"Not Sexist\")\n",
        "    if pred_train[i] == 0:\n",
        "      pred_colour.append(\"Sexist\")\n",
        "\n",
        "test_df = pd.DataFrame({'X':x_, 'Y':y_, 'Z':z_, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='X', y='Y', z='Z', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'rainbow',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVY9fy4NwAi3"
      },
      "source": [
        "Testing Examination End"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cujbqK6wD-z"
      },
      "source": [
        "CLUSTERING RoBERTA PLM Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w6-OXZkwDGT"
      },
      "outputs": [],
      "source": [
        "model.layers[-8].name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2AndHBBv98k"
      },
      "outputs": [],
      "source": [
        "cluster_bert = keras.Model(inputs=model.input, outputs=model.layers[-8].output)\n",
        "with strategy.scope():\n",
        "    test_cl_bert = cluster_bert.predict([test_set_encodings[\"input_ids\"], test_set_encodings[\"attention_mask\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8Vb0vfawnIP"
      },
      "outputs": [],
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y_test_set)):\n",
        "    count = count + 1\n",
        "    x_bert.append(test_cl_bert[i][0])\n",
        "    y_bert.append(test_cl_bert[i][1])\n",
        "    z_bert.append(test_cl_bert[i][2])\n",
        "\n",
        "    if( answer[i] > 0.28 and answer[i] < 0.8 ):\n",
        "        flag_bert.append(2)\n",
        "\n",
        "    if( answer[i] > 0 and answer[i] <= 0.28 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer[i] >= 0.8 and answer[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "print(count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0te1ji2xAP-"
      },
      "source": [
        "k-means PLM Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AluddI1qxAzq"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k21paiXmxCdJ"
      },
      "outputs": [],
      "source": [
        "kmeans_bert = KMeans(n_clusters=3, random_state=44).fit(test_cl_bert)\n",
        "y_kmeans_bert = kmeans_bert.predict(test_cl_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w5_-FG2xD5h"
      },
      "outputs": [],
      "source": [
        "Counter(y_kmeans_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcRGPjoSxY_d"
      },
      "outputs": [],
      "source": [
        "Counter(flag_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfYd9XMVxaGI"
      },
      "outputs": [],
      "source": [
        "# 1 index values are sexist\n",
        "# 0 index values are not sexist\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_bert)):\n",
        "      if flag_bert[i] == 2 and y_kmeans_bert[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3Qi7GUVxeRZ"
      },
      "outputs": [],
      "source": [
        "for i in range(0,len(flag_bert)):\n",
        "    if(y_kmeans_bert[i] == 0):\n",
        "      y_kmeans_bert[i] = 1\n",
        "    elif(y_kmeans_bert[i] == 1):\n",
        "      y_kmeans_bert[i] = 0\n",
        "    else:\n",
        "      y_kmeans_bert[i] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJVjjUsQxgrE"
      },
      "outputs": [],
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y_test_set)):\n",
        "    count = count + 1\n",
        "    x_bert.append(test_cl_bert[i][0])\n",
        "    y_bert.append(test_cl_bert[i][1])\n",
        "    z_bert.append(test_cl_bert[i][2])\n",
        "\n",
        "    if( answer[i] > 0.3 and answer[i] < 0.7 ):\n",
        "        flag_bert.append(2)\n",
        "\n",
        "    if( answer[i] > 0 and answer[i] <= 0.3 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer[i] >= 0.7 and answer[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GAQzUTex09b"
      },
      "outputs": [],
      "source": [
        "Counter(flag_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNjJSx08x3IK"
      },
      "outputs": [],
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_bert, predictions=y_kmeans_bert)\n",
        "print(con_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeTuSCZWx5IY"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_bert, y_kmeans_bert, output_dict=False, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e34TccKx_eK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yrcDhstyBXW"
      },
      "outputs": [],
      "source": [
        "centers_bert = kmeans_bert.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYDXXGg0yDbC"
      },
      "outputs": [],
      "source": [
        "t_svns_off = []\n",
        "for i in range(0,len(Y_test_set)):\n",
        "    off = cosine(test_cl_bert[i], centers_bert[1])/2\n",
        "    t_svns_off.append(1-off)\n",
        "print(len(t_svns_off))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZfJmt5ayFBu"
      },
      "outputs": [],
      "source": [
        "t_svns_noff = []\n",
        "for i in range(0,len(Y_test_set)):\n",
        "    noff = cosine(test_cl_bert[i], centers_bert[0])/2\n",
        "    t_svns_noff.append(1-noff)\n",
        "print(len(t_svns_noff))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZcDSlqnyV5-"
      },
      "outputs": [],
      "source": [
        "t_svns_neu = []\n",
        "for i in range(0,len(Y_test_set)):\n",
        "    neu = cosine(test_cl_bert[i], centers_bert[2])/2\n",
        "    t_svns_neu.append(1-neu)\n",
        "print(len(t_svns_neu))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMTGpyoKylwb"
      },
      "source": [
        "k-means PLM plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcSHwBNHyj0w"
      },
      "outputs": [],
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0hO3uz5yok0"
      },
      "outputs": [],
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(Y_test_set)):\n",
        "    if y_kmeans_bert[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_bert[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_bert[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':t_svns_off, 'SVNS Not Offensive':t_svns_noff, 'SVNS Neutral':t_svns_neu, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    },\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vk56U6S1y1Zy"
      },
      "outputs": [],
      "source": [
        "pred_krobert = []\n",
        "# Assuming svns_off, svns_neu, and svns_noff are arrays or lists\n",
        "for i in range(len(Y_test_set)):\n",
        "    if(t_svns_off[i] > t_svns_neu[i]+t_svns_noff[i]):\n",
        "      pred_krobert.append(0)\n",
        "    elif (t_svns_noff[i] > t_svns_neu[i] and t_svns_noff[i] > t_svns_off[i]):\n",
        "      pred_krobert.append(1)\n",
        "    elif (t_svns_neu[i]>t_svns_noff[i] and t_svns_neu[i]>t_svns_off[i]):\n",
        "      pred_krobert.append(1)\n",
        "    else:\n",
        "      pred_krobert.append(0)\n",
        "print(classification_report(Y_test_set, pred_krobert, output_dict=False, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beCgwK8ef_B9"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X = list(zip(svns_off, svns_neu, svns_noff))\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "pred_krobert = decision_tree.predict(X_test)\n",
        "print(classification_report(Y_test, pred_krobert, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA3hqmH5b_Yw"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming svns_off, svns_neu, svns_noff, and Y are defined\n",
        "\n",
        "# Prepare the data\n",
        "X = list(zip(svns_off, svns_neu, svns_noff))\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "\n",
        "# Predict on the training set\n",
        "pred_train = decision_tree.predict(X_train)\n",
        "\n",
        "# Predict on the test set\n",
        "pred_test = decision_tree.predict(X_test)\n",
        "\n",
        "# Calculate train accuracy\n",
        "train_accuracy = accuracy_score(Y_train, pred_train)\n",
        "print(f'Train Accuracy: {train_accuracy:.3f}')\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = accuracy_score(Y_test, pred_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.3f}')\n",
        "\n",
        "# Print classification report for the test set\n",
        "print(classification_report(Y_test, pred_test, digits=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HZboAzPzY0Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X_train = list(zip(svns_off, svns_neu, svns_noff))\n",
        "X_test = list(zip(t_svns_off, t_svns_neu, t_svns_noff))\n",
        "\n",
        "Y_train=Y\n",
        "Y_test=Y_test_set\n",
        "\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "pred_krobert = decision_tree.predict(X_test)\n",
        "print(classification_report(Y_test, pred_krobert, digits=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCrAkXbzYHYS"
      },
      "source": [
        "Validation Explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qef2Ih_UaKkl"
      },
      "outputs": [],
      "source": [
        "answer_val = model.predict([test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aus0kgajYJOR"
      },
      "outputs": [],
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3tQzHBvZmlp"
      },
      "outputs": [],
      "source": [
        "# 3 neuron output\n",
        "model.layers[-6].name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouzCu92RZodp"
      },
      "outputs": [],
      "source": [
        "cluster_dense_3 = keras.Model(inputs=model.input, outputs=model.layers[-6].output)\n",
        "with strategy.scope():\n",
        "    val_3 = cluster_dense_3.predict([test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fyk01cNZ3aC"
      },
      "outputs": [],
      "source": [
        "pred_train = []\n",
        "temp = 0\n",
        "\n",
        "for i in range(0,len(Y_vali)):\n",
        "\n",
        "    num = answer_val[i]\n",
        "\n",
        "    if(num >= 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred_train.append(num)\n",
        "\n",
        "print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWkOLQGdaBnU"
      },
      "outputs": [],
      "source": [
        "flag = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y_vali)):\n",
        "    count = count + 1\n",
        "    x_.append(val_3[i][1])\n",
        "    y_.append(val_3[i][0])\n",
        "    z_.append(val_3[i][2])\n",
        "\n",
        "    if( answer_val[i] > 0.3 and answer_val[i] < 0.7 ):\n",
        "        flag.append(2)\n",
        "\n",
        "    if( answer_val[i] > 0 and answer_val[i] <= 0.3 ):\n",
        "        flag.append(0)\n",
        "\n",
        "    if( answer_val[i] >= 0.7 and answer_val[i] < 1 ):\n",
        "        flag.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AtZo6M-asAD"
      },
      "outputs": [],
      "source": [
        "Counter(flag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSB46HXxauFM"
      },
      "outputs": [],
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_vali, predictions=pred_train)\n",
        "print(con_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbMTVmNbawDJ"
      },
      "outputs": [],
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(flag)):\n",
        "    if flag[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if flag[i] == 1:\n",
        "      pred_colour.append(\"Not sexist\")\n",
        "    if flag[i] == 0:\n",
        "      pred_colour.append(\"Sexist\")\n",
        "\n",
        "test_df = pd.DataFrame({'x':x_, 'y':y_, 'z':z_, 'Labels':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='x', y='y', z='z', color='Labels')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 0.7,\n",
        "        'colorscale' : 'Oryel',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 750, height = 500)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lyETMeWbAFm"
      },
      "outputs": [],
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(flag)):\n",
        "    if pred_train[i] == 1:\n",
        "      pred_colour.append(\"Not Sexist\")\n",
        "    if pred_train[i] == 0:\n",
        "      pred_colour.append(\"Sexist\")\n",
        "\n",
        "test_df = pd.DataFrame({'X':x_, 'Y':y_, 'Z':z_, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='X', y='Y', z='Z', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'rainbow',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxY0pccbbLlw"
      },
      "source": [
        "Validation Examination End"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1_LS0qqbPbF"
      },
      "source": [
        "CLUSTERING RoBERTA PLM Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0KHyN4ubLH4"
      },
      "outputs": [],
      "source": [
        "model.layers[-8].name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5YfPUvHbULV"
      },
      "outputs": [],
      "source": [
        "cluster_bert = keras.Model(inputs=model.input, outputs=model.layers[-8].output)\n",
        "with strategy.scope():\n",
        "    val_cl_bert = cluster_bert.predict([test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKxKT8RIcfeo"
      },
      "outputs": [],
      "source": [
        "len(Y_vali)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMJEpYr8bawS"
      },
      "outputs": [],
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y_vali)):\n",
        "    count = count + 1\n",
        "    x_bert.append(val_cl_bert[i][0])\n",
        "    y_bert.append(val_cl_bert[i][1])\n",
        "    z_bert.append(val_cl_bert[i][2])\n",
        "\n",
        "    if( answer_val[i] > 0.28 and answer_val[i] < 0.8 ):\n",
        "        flag_bert.append(2)\n",
        "\n",
        "    if( answer_val[i] > 0 and answer_val[i] <= 0.28 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_val[i] >= 0.8 and answer_val[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsPgRDixb0WT"
      },
      "source": [
        "K-Means PLM Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6zPtmOUbxGK"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIfUXUgub7uD"
      },
      "outputs": [],
      "source": [
        "kmeans_bert = KMeans(n_clusters=3, random_state=44).fit(val_cl_bert)\n",
        "y_kmeans_bert = kmeans_bert.predict(val_cl_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQd58B_ccBxf"
      },
      "outputs": [],
      "source": [
        "Counter(y_kmeans_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2awfTvocDRd"
      },
      "outputs": [],
      "source": [
        "Counter(flag_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqa1pplvcZV3"
      },
      "outputs": [],
      "source": [
        "len(flag_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV2WijT8cFBs"
      },
      "outputs": [],
      "source": [
        "# 1 index values are sexist\n",
        "# 0 index values are not sexist\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_bert)):\n",
        "      if flag_bert[i] == 2 and y_kmeans_bert[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTnZGKIycHs5"
      },
      "outputs": [],
      "source": [
        "for i in range(0,len(flag_bert)):\n",
        "    if(y_kmeans_bert[i] == 0):\n",
        "      y_kmeans_bert[i] = 1\n",
        "    elif(y_kmeans_bert[i] == 1):\n",
        "      y_kmeans_bert[i] = 0\n",
        "    else:\n",
        "      y_kmeans_bert[i] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-j1ANvmC-1l"
      },
      "outputs": [],
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y_vali)):\n",
        "    count = count + 1\n",
        "    x_bert.append(val_cl_bert[i][0])\n",
        "    y_bert.append(val_cl_bert[i][1])\n",
        "    z_bert.append(val_cl_bert[i][2])\n",
        "\n",
        "    if( answer_val[i] > 0.3 and answer_val[i] < 0.7 ):\n",
        "        flag_bert.append(2)\n",
        "\n",
        "    if( answer_val[i] > 0 and answer_val[i] <= 0.3 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_val[i] >= 0.7 and answer_val[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iS8WTLxDCnD"
      },
      "outputs": [],
      "source": [
        "Counter(flag_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp_ANuFkDFFW"
      },
      "outputs": [],
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_bert, predictions=y_kmeans_bert)\n",
        "print(con_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-ISFb69DcNc"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_bert, y_kmeans_bert, output_dict=False, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaIiUoWNDefd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Kn9IgNsDhEg"
      },
      "outputs": [],
      "source": [
        "centers_bert = kmeans_bert.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qSU3I_IDjyl"
      },
      "outputs": [],
      "source": [
        "v_svns_off = []\n",
        "for i in range(0,len(Y_vali)):\n",
        "    off = cosine(val_cl_bert[i], centers_bert[1])/2\n",
        "    v_svns_off.append(1-off)\n",
        "print(len(v_svns_off))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI8MoJ5nDu9N"
      },
      "outputs": [],
      "source": [
        "v_svns_noff = []\n",
        "for i in range(0,len(Y_vali)):\n",
        "    noff = cosine(val_cl_bert[i], centers_bert[0])/2\n",
        "    v_svns_noff.append(1-noff)\n",
        "print(len(v_svns_noff))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pqsoWTQD3AZ"
      },
      "outputs": [],
      "source": [
        "v_svns_neu = []\n",
        "for i in range(0,len(Y_vali)):\n",
        "    neu = cosine(val_cl_bert[i], centers_bert[2])/2\n",
        "    v_svns_neu.append(1-neu)\n",
        "print(len(v_svns_neu))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MOv2-B_EFeY"
      },
      "source": [
        "K-Means PLM Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9vRP3ieECqN"
      },
      "outputs": [],
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXhviwKhEI43"
      },
      "outputs": [],
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(Y_vali)):\n",
        "    if y_kmeans_bert[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_bert[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_bert[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':v_svns_off, 'SVNS Not Offensive':v_svns_noff, 'SVNS Neutral':v_svns_neu, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    },\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O9vtIAfEYHE"
      },
      "outputs": [],
      "source": [
        "pred_krobert = []\n",
        "# Assuming svns_off, svns_neu, and svns_noff are arrays or lists\n",
        "for i in range(len(Y_vali)):\n",
        "    if(v_svns_off[i] > v_svns_neu[i]+v_svns_noff[i]):\n",
        "      pred_krobert.append(0)\n",
        "    elif (v_svns_noff[i] > v_svns_neu[i] and v_svns_noff[i] > v_svns_off[i]):\n",
        "      pred_krobert.append(1)\n",
        "    elif (v_svns_neu[i]>v_svns_noff[i] and v_svns_neu[i]>v_svns_off[i]):\n",
        "      pred_krobert.append(1)\n",
        "    else:\n",
        "      pred_krobert.append(0)\n",
        "print(classification_report(Y_vali, pred_krobert, output_dict=False, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EToi5qLqP5Qg"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Prepare the data\n",
        "X = list(zip(svns_off, svns_neu, svns_noff))\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "\n",
        "# Predict on the training set\n",
        "pred_train = decision_tree.predict(X_train)\n",
        "\n",
        "# Predict on the test set\n",
        "pred_test = decision_tree.predict(X_test)\n",
        "\n",
        "# Calculate train accuracy\n",
        "train_accuracy = accuracy_score(Y_train, pred_train)\n",
        "print(f'Train Accuracy: {train_accuracy:.3f}')\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = accuracy_score(Y_test, pred_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.3f}')\n",
        "\n",
        "# Print classification report for the test set\n",
        "print(classification_report(Y_test, pred_test, digits=3))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}