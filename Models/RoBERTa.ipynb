{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "OLID RoBERTa Github.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "acf39ad219de4d729f4c71ac5deaae79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5759f89f03b245a3bfe7228b221c933b",
              "IPY_MODEL_eb2917c7bea546bfab4ae7867a636aac",
              "IPY_MODEL_f9b90f1432d244f1ae650acbf6ca6723"
            ],
            "layout": "IPY_MODEL_0dd6707e7a7b49c7944509db76043ab6"
          }
        },
        "5759f89f03b245a3bfe7228b221c933b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbc7817ba3e845dd87e86ea59c3ac604",
            "placeholder": "​",
            "style": "IPY_MODEL_ae8081b451114012a3c378d1340603ea",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "eb2917c7bea546bfab4ae7867a636aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e95c954dc1b4dcaa02f7f6266f3f35c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0c8a0a67e1643b2a7136f5d99757eec",
            "value": 25
          }
        },
        "f9b90f1432d244f1ae650acbf6ca6723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4417690250ca47b29f9c8249beaba424",
            "placeholder": "​",
            "style": "IPY_MODEL_a4fc7b8c7356400183412b2cfc7a6702",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.38kB/s]"
          }
        },
        "0dd6707e7a7b49c7944509db76043ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc7817ba3e845dd87e86ea59c3ac604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae8081b451114012a3c378d1340603ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e95c954dc1b4dcaa02f7f6266f3f35c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0c8a0a67e1643b2a7136f5d99757eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4417690250ca47b29f9c8249beaba424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4fc7b8c7356400183412b2cfc7a6702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed3a5362c51148e0bb4132ade646c96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a242b6b9f29b476ea87c98628cfb22a6",
              "IPY_MODEL_67fc694248ba428aba99f6dd5077ffa1",
              "IPY_MODEL_5518f2781dbd4f34ab7ab40d612496a6"
            ],
            "layout": "IPY_MODEL_a318714be08541c6b1c894c8db3469ca"
          }
        },
        "a242b6b9f29b476ea87c98628cfb22a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f21a65a8bcf40c7ad11ca36f2421681",
            "placeholder": "​",
            "style": "IPY_MODEL_7a587973ad6a407c8934f94b44b8943b",
            "value": "vocab.json: 100%"
          }
        },
        "67fc694248ba428aba99f6dd5077ffa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0491c94154e4538838479692484d7d4",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d4a430b61d9423186d817219ad7fcd6",
            "value": 898823
          }
        },
        "5518f2781dbd4f34ab7ab40d612496a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bcb1a8a75a34b32a13bdc2bb7aa3c2e",
            "placeholder": "​",
            "style": "IPY_MODEL_d16080723fea42a9a5a72f9c847c1d76",
            "value": " 899k/899k [00:00&lt;00:00, 5.86MB/s]"
          }
        },
        "a318714be08541c6b1c894c8db3469ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f21a65a8bcf40c7ad11ca36f2421681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a587973ad6a407c8934f94b44b8943b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0491c94154e4538838479692484d7d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d4a430b61d9423186d817219ad7fcd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bcb1a8a75a34b32a13bdc2bb7aa3c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d16080723fea42a9a5a72f9c847c1d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8416e009706c480b90cb61b9d6eeacd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_648959b54a284b52b483c97b9923dae6",
              "IPY_MODEL_c3e4a359c24846be9d0a24bcb7c8e2ff",
              "IPY_MODEL_81f19325ba8648e2a46b822d9621acad"
            ],
            "layout": "IPY_MODEL_a0f7803244b74c788c6e08eed2ce1a0d"
          }
        },
        "648959b54a284b52b483c97b9923dae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80ebe69d60d4c0ca8b6dc082dfbad1a",
            "placeholder": "​",
            "style": "IPY_MODEL_21eb300959dc4fd58ed746dfef69b01c",
            "value": "merges.txt: 100%"
          }
        },
        "c3e4a359c24846be9d0a24bcb7c8e2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_529bd20738074a9b8423c60d60abfb12",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65fcb3652fa2466d81539303d26f8c98",
            "value": 456318
          }
        },
        "81f19325ba8648e2a46b822d9621acad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ca5c125875e4bfd86cc1abeb51d4087",
            "placeholder": "​",
            "style": "IPY_MODEL_b79dd290afe242a2aa77680eee01d92e",
            "value": " 456k/456k [00:00&lt;00:00, 2.45MB/s]"
          }
        },
        "a0f7803244b74c788c6e08eed2ce1a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80ebe69d60d4c0ca8b6dc082dfbad1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21eb300959dc4fd58ed746dfef69b01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "529bd20738074a9b8423c60d60abfb12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65fcb3652fa2466d81539303d26f8c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ca5c125875e4bfd86cc1abeb51d4087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b79dd290afe242a2aa77680eee01d92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c06d459ba2b84a05a33f5fb754b9ec94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4fbfe7b525c4e0aa7b45e90a84c8533",
              "IPY_MODEL_8ba2bc9043804a7fa364726100bb8d90",
              "IPY_MODEL_7aae70d0a9704272a0672104dd1a9dd5"
            ],
            "layout": "IPY_MODEL_b58eaae58ade45899599b5afd527e1e5"
          }
        },
        "e4fbfe7b525c4e0aa7b45e90a84c8533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bda443c6722422392b0559d8456375b",
            "placeholder": "​",
            "style": "IPY_MODEL_b856c65ed71c495e9e17e0e13859921e",
            "value": "tokenizer.json: 100%"
          }
        },
        "8ba2bc9043804a7fa364726100bb8d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46ca5d37537c433187707531803a2672",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9265634e0f8448408751a12aeb226756",
            "value": 1355863
          }
        },
        "7aae70d0a9704272a0672104dd1a9dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efd3a2ba4e244ebd8e7a0fac6c996ac1",
            "placeholder": "​",
            "style": "IPY_MODEL_424d36ad141343979bd93749e2f798f4",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 6.11MB/s]"
          }
        },
        "b58eaae58ade45899599b5afd527e1e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bda443c6722422392b0559d8456375b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b856c65ed71c495e9e17e0e13859921e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46ca5d37537c433187707531803a2672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9265634e0f8448408751a12aeb226756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efd3a2ba4e244ebd8e7a0fac6c996ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "424d36ad141343979bd93749e2f798f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4026f511f684a45b176e99dd6bf6646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ca175a4b7184778b8d7adf4f8152865",
              "IPY_MODEL_4a1db13761c244739ccc64a5c45344e5",
              "IPY_MODEL_5102be6473b14e1e94817d331dabeb08"
            ],
            "layout": "IPY_MODEL_36846505eff3426291d5974b1df58438"
          }
        },
        "9ca175a4b7184778b8d7adf4f8152865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f794688d064884ba7a955ff96ede55",
            "placeholder": "​",
            "style": "IPY_MODEL_85af9b4f07044edba0d76f5effbc7450",
            "value": "config.json: 100%"
          }
        },
        "4a1db13761c244739ccc64a5c45344e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1e6193911394576a52994245fd1f30c",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60ab6cf3a10f422c95b9172b0af7ebb9",
            "value": 481
          }
        },
        "5102be6473b14e1e94817d331dabeb08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b04e184e11e403ca9f40760d2f04694",
            "placeholder": "​",
            "style": "IPY_MODEL_3f7862773fc542f79ccdc00bd1ba590a",
            "value": " 481/481 [00:00&lt;00:00, 11.8kB/s]"
          }
        },
        "36846505eff3426291d5974b1df58438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15f794688d064884ba7a955ff96ede55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85af9b4f07044edba0d76f5effbc7450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1e6193911394576a52994245fd1f30c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60ab6cf3a10f422c95b9172b0af7ebb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b04e184e11e403ca9f40760d2f04694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f7862773fc542f79ccdc00bd1ba590a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHijuspuuMkO",
        "outputId": "1eb2a119-b81e-4739-c366-51f7fb64f963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u6oSdNWHhpm",
        "outputId": "41fa7483-0c76-4f39-b6fb-a8b6f746f0eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/590.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N_7mKSDF2X0",
        "outputId": "33f44f9d-4409-4a59-ba74-83f183969b0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ekphrasis"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ekphrasis\n",
            "  Downloading ekphrasis-0.5.4-py3-none-any.whl.metadata (610 bytes)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ekphrasis) (3.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ekphrasis) (4.67.1)\n",
            "Collecting colorama (from ekphrasis)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting ujson (from ekphrasis)\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from ekphrasis) (3.10.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from ekphrasis) (3.9.1)\n",
            "Collecting ftfy (from ekphrasis)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ekphrasis) (2.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->ekphrasis) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ekphrasis) (2.9.0.post0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->ekphrasis) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->ekphrasis) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->ekphrasis) (2024.11.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->ekphrasis) (1.17.0)\n",
            "Downloading ekphrasis-0.5.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ujson, ftfy, colorama, ekphrasis\n",
            "Successfully installed colorama-0.4.6 ekphrasis-0.5.4 ftfy-6.3.1 ujson-5.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZRAL3V1w2w_",
        "outputId": "fdfa42c2-d887-4b32-f160-9d688ac34129",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install plotly==4.5.4"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plotly==4.5.4\n",
            "  Downloading plotly-4.5.4-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting retrying>=1.3.3 (from plotly==4.5.4)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from plotly==4.5.4) (1.17.0)\n",
            "Downloading plotly-4.5.4-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: retrying, plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "Successfully installed plotly-4.5.4 retrying-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1BgltZfpfIb",
        "outputId": "c5f8f35f-958b-4bf0-f691-ab1c90160a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers==4.2.1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.2.1\n",
            "  Downloading transformers-4.2.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.2.1) (3.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from transformers==4.2.1) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from transformers==4.2.1) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.2.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.2.1) (2.32.3)\n",
            "Collecting sacremoses (from transformers==4.2.1)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting tokenizers==0.9.4 (from transformers==4.2.1)\n",
            "  Downloading tokenizers-0.9.4.tar.gz (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.2/184.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.2.1) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.2.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.2.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.2.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.2.1) (2025.4.26)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses->transformers==4.2.1) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses->transformers==4.2.1) (1.4.2)\n",
            "Downloading transformers-4.2.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tokenizers\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR494XZ0FZ5h"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import os\n",
        "\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjOCTC2LFZ5p",
        "outputId": "fe93ba19-4e44-4517-9090-4228c85f3b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text_processor = TextPreProcessor(\n",
        "    # terms that will be normalized\n",
        "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "        'time', 'url', 'date', 'number'],\n",
        "    # terms that will be annotated\n",
        "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "        'emphasis', 'censored'},\n",
        "    fix_html=True,  # fix HTML tokens\n",
        "\n",
        "    # corpus from which the word statistics are going to be used\n",
        "    # for word segmentation\n",
        "    segmenter=\"twitter\",\n",
        "\n",
        "    # corpus from which the word statistics are going to be used\n",
        "    # for spell correction\n",
        "    corrector=\"twitter\",\n",
        "\n",
        "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
        "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
        "    spell_correct_elong=True,  # spell correction for elongated words\n",
        "\n",
        "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
        "    # the tokenizer, should take as input a string and return a list of tokens\n",
        "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "\n",
        "    # list of dictionaries, for replacing tokens extracted from the text,\n",
        "    # with other expressions. You can pass more than one dictionaries.\n",
        "    dicts=[emoticons]\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word statistics files not found!\n",
            "Downloading... done!\n",
            "Unpacking... done!\n",
            "Reading twitter - 1grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_1grams.txt\n",
            "Reading twitter - 2grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_2grams.txt\n",
            "Reading twitter - 1grams ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBrkiHZsFZ5v"
      },
      "source": [
        "def print_text(texts,i,j):\n",
        "    for u in range(i,j):\n",
        "        print(texts[u])\n",
        "        print()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC2SiOlMFZ51",
        "outputId": "eb18549a-1f87-46f4-db77-58853fcb0a40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/offenseval/olid-training-v1.0.tsv',delimiter='\\t',encoding='utf-8')\n",
        "print(list(df.columns.values)) #file header\n",
        "print(df.head(5)) #last N rows"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['id', 'tweet', 'subtask_a', 'subtask_b', 'subtask_c']\n",
            "      id                                              tweet subtask_a  \\\n",
            "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
            "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
            "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
            "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
            "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
            "\n",
            "  subtask_b subtask_c  \n",
            "0       UNT       NaN  \n",
            "1       TIN       IND  \n",
            "2       NaN       NaN  \n",
            "3       UNT       NaN  \n",
            "4       NaN       NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5uO1nfcyhw7"
      },
      "source": [
        "df.replace(np.nan, 'NA', inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDSHL-Uz13Aj",
        "outputId": "ecba3e41-f32d-4e46-85e2-3498aa7a4f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                              tweet subtask_a  \\\n",
              "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
              "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
              "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
              "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
              "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
              "\n",
              "  subtask_b subtask_c  \n",
              "0       UNT        NA  \n",
              "1       TIN       IND  \n",
              "2        NA        NA  \n",
              "3       UNT        NA  \n",
              "4        NA        NA  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbd90d32-f42d-45fd-b101-2002b578defb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NA</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NA</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbd90d32-f42d-45fd-b101-2002b578defb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cbd90d32-f42d-45fd-b101-2002b578defb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cbd90d32-f42d-45fd-b101-2002b578defb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fdfb0c85-4777-4c6f-b15c-ff8244f8788a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fdfb0c85-4777-4c6f-b15c-ff8244f8788a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fdfb0c85-4777-4c6f-b15c-ff8244f8788a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 13240,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26092,\n        \"min\": 10006,\n        \"max\": 99986,\n        \"num_unique_values\": 13240,\n        \"samples\": [\n          27650,\n          52965,\n          87438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13207,\n        \"samples\": [\n          \"60 and hopeful to someday meet a classy gal that I can talk to about MAGA and WWG1WGA!  Have yet to find!  Having way to much fun now not to share :-) URL\",\n          \"@USER DJT2- You have to remember his daughter is married to am Iranian and so he defends them at all costs. He is a coward and a disgrace. Thank GOD for your Dad or we would all be in a World of hurt!\",\n          \"@USER @USER @USER @USER @USER hey #sickholder were you the dirty filthy greasy cheesy negarrrr who was in contempt of Congress? Don't open your mouth it's extremely stink.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subtask_a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NOT\",\n          \"OFF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subtask_b\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"UNT\",\n          \"TIN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subtask_c\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"IND\",\n          \"GRP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEVYS5LfFZ57",
        "outputId": "a6e9fffc-3c95-4b1c-da91-06cf0ee50bff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text_array = df[\"tweet\"]\n",
        "labels = df[\"subtask_a\"]\n",
        "labels_target = df[\"subtask_b\"]\n",
        "print(len(text_array))\n",
        "print_text(text_array,0,10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13240\n",
            "@USER She should ask a few native Americans what their take on this is.\n",
            "\n",
            "@USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL\n",
            "\n",
            "Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
            "\n",
            "@USER Someone should'veTaken\" this piece of shit to a volcano. 😂\"\n",
            "\n",
            "@USER @USER Obama wanted liberals &amp; illegals to move into red states\n",
            "\n",
            "@USER Liberals are all Kookoo !!!\n",
            "\n",
            "@USER @USER Oh noes! Tough shit.\n",
            "\n",
            "@USER was literally just talking about this lol all mass shootings like that have been set ups. it’s propaganda used to divide us on major issues like gun control and terrorism\n",
            "\n",
            "@USER Buy more icecream!!!\n",
            "\n",
            "@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiJRyIwRiTEi"
      },
      "source": [
        "original = text_array"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbgC7u_4jIO7"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvsUCosR5ck9",
        "outputId": "51529f0b-d82d-4ef8-9c29-342a960fcdd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "df_test_labels_b = pd.read_csv('/content/drive/My Drive/offenseval/labels-levelb.csv', header=None)\n",
        "print(len(df_test_labels_b))\n",
        "lol = df_test_labels_b[1]\n",
        "print(Counter(lol))\n",
        "df_test_labels_b.head(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240\n",
            "Counter({'TIN': 213, 'UNT': 27})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0    1\n",
              "0  15923  TIN\n",
              "1  60133  TIN\n",
              "2  83681  TIN\n",
              "3  65507  TIN\n",
              "4  12588  UNT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe061be5-b30e-4e38-9db6-ed8e5c7f4fa5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15923</td>\n",
              "      <td>TIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60133</td>\n",
              "      <td>TIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>83681</td>\n",
              "      <td>TIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65507</td>\n",
              "      <td>TIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12588</td>\n",
              "      <td>UNT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe061be5-b30e-4e38-9db6-ed8e5c7f4fa5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe061be5-b30e-4e38-9db6-ed8e5c7f4fa5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe061be5-b30e-4e38-9db6-ed8e5c7f4fa5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d7f3c5d9-cf87-46a6-8ff1-98aa0762419f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7f3c5d9-cf87-46a6-8ff1-98aa0762419f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d7f3c5d9-cf87-46a6-8ff1-98aa0762419f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test_labels_b",
              "summary": "{\n  \"name\": \"df_test_labels_b\",\n  \"rows\": 240,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25636,\n        \"min\": 10684,\n        \"max\": 99563,\n        \"num_unique_values\": 240,\n        \"samples\": [\n          27550,\n          49139,\n          60466\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"UNT\",\n          \"TIN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr6FcNLp8QzI"
      },
      "source": [
        "labels_target_test = []"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNkBXvuXFZ6B",
        "outputId": "1630c298-18fb-4861-b46a-0a2a7c58d62a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_test_text = pd.read_csv('/content/drive/My Drive/offenseval/testset-levela.tsv',delimiter='\\t',encoding='utf-8')\n",
        "print(list(df_test_text.columns.values)) #file header\n",
        "print(df_test_text.head(5)) #first N rows\n",
        "\n",
        "df_test_labels = pd.read_csv('/content/drive/My Drive/offenseval/labels-levela.csv', header=None)\n",
        "print(list(df_test_labels.columns.values))\n",
        "print(df_test_labels.head(5))\n",
        "\n",
        "count = 0\n",
        "j = 0\n",
        "for i in range(0,len(df_test_text[\"id\"])):\n",
        "    if df_test_labels[1][i] == \"OFF\":\n",
        "        if df_test_labels[0][i] == df_test_labels_b[0][j]:\n",
        "            labels_target_test.append(df_test_labels_b[1][j])\n",
        "            j = j + 1\n",
        "    else:\n",
        "        labels_target_test.append(\"NA\")\n",
        "\n",
        "print(len(df_test_text[\"id\"]))\n",
        "print(count)\n",
        "\n",
        "text_array_test = df_test_text[\"tweet\"]\n",
        "labels_test = df_test_labels[1]\n",
        "print(\"Checking length of validation set\")\n",
        "print(len(text_array_test),len(labels_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['id', 'tweet']\n",
            "      id                                              tweet\n",
            "0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...\n",
            "1  27014  #ConstitutionDay is revered by Conservatives, ...\n",
            "2  30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...\n",
            "3  13876  #Watching #Boomer getting the news that she is...\n",
            "4  60133  #NoPasaran: Unity demo to oppose the far-right...\n",
            "[np.int64(0), np.int64(1)]\n",
            "       0    1\n",
            "0  15923  OFF\n",
            "1  27014  NOT\n",
            "2  30530  NOT\n",
            "3  13876  NOT\n",
            "4  60133  OFF\n",
            "860\n",
            "0\n",
            "Checking length of validation set\n",
            "860 860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6jRCqVmQX4J"
      },
      "source": [
        "original_test = text_array_test"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bSNIGHn7ZNl",
        "outputId": "7a4fad52-1fc8-49bb-afcf-9a0cbb1fccb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Counter(labels_target_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'TIN': 213, 'NA': 620, 'UNT': 27})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkOC5ONKFZ6I",
        "outputId": "b410ea60-78ef-453c-eeb2-e086aedec87f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_website(text):\n",
        "    pattern = re.compile(r'(?i)\\b(?:https?://\\S+|www\\.\\S+|\\S+\\.(com|co|net)\\b)')\n",
        "    return \" \".join([word if not pattern.search(word) else \"\" for word in text.split()])\n",
        "\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: remove_website(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: remove_website(text))\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@USER She should ask a few native Americans what their take on this is.\n",
            "\n",
            "@USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL\n",
            "\n",
            "Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
            "\n",
            "@USER Someone should'veTaken\" this piece of shit to a volcano. 😂\"\n",
            "\n",
            "@USER @USER Obama wanted liberals &amp; illegals to move into red states\n",
            "\n",
            "@USER Liberals are all Kookoo !!!\n",
            "\n",
            "@USER @USER Oh noes! Tough shit.\n",
            "\n",
            "@USER was literally just talking about this lol all mass shootings like that have been set ups. it’s propaganda used to divide us on major issues like gun control and terrorism\n",
            "\n",
            "@USER Buy more icecream!!!\n",
            "\n",
            "@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo\n",
            "\n",
            "**************************************************************************\n",
            "#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA Democrats Support Antifa, Muslim Brotherhood, MS13, ISIS, Pedophilia, Child Trafficking, Taxpayer Funded Abortion’s, Election Fraud, Sedition And Treason!!! #LockThemAllUp #WWG1WGA #QAnon ⁦@USER URL\n",
            "\n",
            "#ConstitutionDay is revered by Conservatives, hated by Progressives/Socialist/Democrats that want to change it.\n",
            "\n",
            "#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendment #RNC #USMC #veterans @USER @USER @USER @USER @USER #fakereporting #THESWAMP #dnc #liberals @USER @USER #fakeoutrage @USER First, it reduces the ca URL\n",
            "\n",
            "#Watching #Boomer getting the news that she is still up for parole always makes me smile. #Wentworth Finale...@USER is such a treasure. URL\n",
            "\n",
            "#NoPasaran: Unity demo to oppose the far-right in #London – #antifa #Oct13 — Enough is Enough! URL\n",
            "\n",
            ". . . What the fuck did he do this time?\n",
            "\n",
            "#RAP is a form of ART! Used to express yourself freely. It does not gv the green light or excuse the behavior of acting like an animal! She is not in the streets of the BX where violence is a way of living. Elevate yourself boo and get on @USER level for longevity! #QUEEN👑\n",
            "\n",
            "@USER Do you get the feeling he is kissing @USER behind so he can humiliate him later?\n",
            "\n",
            "5 Tips to Enhance Audience Connection on Facebook URL @USER #socialmedia #smm URL\n",
            "\n",
            "#BiggBossTamil janani won the task. She is going to first final list👏👏👏👏\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKBHJaEkFZ6N"
      },
      "source": [
        "# Functions for chat word conversion\n",
        "f = open(\"/content/drive/My Drive/offenseval/slang.txt\", \"r\")\n",
        "chat_words_str = f.read()\n",
        "chat_words_map_dict = {}\n",
        "chat_words_list = []\n",
        "\n",
        "for line in chat_words_str.split(\"\\n\"):\n",
        "    if line != \"\":\n",
        "        cw = line.split(\"=\")[0]\n",
        "        cw_expanded = line.split(\"=\")[1]\n",
        "        chat_words_list.append(cw)\n",
        "        chat_words_map_dict[cw] = cw_expanded\n",
        "chat_words_list = set(chat_words_list)\n",
        "\n",
        "def chat_words_conversion(text):\n",
        "    new_text = []\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_words_list:\n",
        "            new_text.append(chat_words_map_dict[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8bYKRrNFZ6R",
        "outputId": "db1eb678-5eb8-411c-e0a4-6df09f5e7e24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Chat word conversion\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(text_array,0,10)\n",
        "print_text(original,0,10)\n",
        "\n",
        "print(\"********************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@USER She should ask a few native Americans what their take on this is.\n",
            "\n",
            "@USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL\n",
            "\n",
            "Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
            "\n",
            "@USER Someone should'veTaken\" this piece of shit to a volcano. 😂\"\n",
            "\n",
            "@USER @USER Obama wanted liberals &amp; illegals to move into red states\n",
            "\n",
            "@USER Liberals are all Kookoo !!!\n",
            "\n",
            "@USER @USER Oh noes! Tough shit.\n",
            "\n",
            "@USER was literally just talking about this Laughing Out Loud all mass shootings like that have been set ups. it’s propaganda used to divide us on major issues like gun control and terrorism\n",
            "\n",
            "@USER Buy more icecream!!!\n",
            "\n",
            "@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo\n",
            "\n",
            "@USER She should ask a few native Americans what their take on this is.\n",
            "\n",
            "@USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL\n",
            "\n",
            "Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
            "\n",
            "@USER Someone should'veTaken\" this piece of shit to a volcano. 😂\"\n",
            "\n",
            "@USER @USER Obama wanted liberals &amp; illegals to move into red states\n",
            "\n",
            "@USER Liberals are all Kookoo !!!\n",
            "\n",
            "@USER @USER Oh noes! Tough shit.\n",
            "\n",
            "@USER was literally just talking about this lol all mass shootings like that have been set ups. it’s propaganda used to divide us on major issues like gun control and terrorism\n",
            "\n",
            "@USER Buy more icecream!!!\n",
            "\n",
            "@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo\n",
            "\n",
            "********************************************************************************\n",
            "#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA Democrats Support Antifa, Muslim Brotherhood, MS13, ISIS, Pedophilia, Child Trafficking, Taxpayer Funded Abortion’s, Election Fraud, Sedition And Treason!!! #LockThemAllUp #WWG1WGA #QAnon ⁦@USER URL\n",
            "\n",
            "#ConstitutionDay is revered by Conservatives, hated by Progressives/Socialist/Democrats that want to change it.\n",
            "\n",
            "#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendment #RNC #USMC #veterans @USER @USER @USER @USER @USER #fakereporting #THESWAMP #dnc #liberals @USER @USER #fakeoutrage @USER First, it reduces the ca URL\n",
            "\n",
            "#Watching #Boomer getting the news that she is still up for parole always makes me smile. #Wentworth Finale...@USER is such a treasure. URL\n",
            "\n",
            "#NoPasaran: Unity demo to oppose the far-right in #London – #antifa #Oct13 — Enough is Enough! URL\n",
            "\n",
            ". . . What the fuck did he do this time?\n",
            "\n",
            "#RAP is a form of ART! Used to express yourself freely. It does not gv the green light or excuse the behavior of acting like an animal! She is not in the streets of the BX where violence is a way of living. Elevate yourself boo and get on @USER level for longevity! #QUEEN👑\n",
            "\n",
            "@USER Do you get the feeling he is kissing @USER behind so he can humiliate him later?\n",
            "\n",
            "5 Tips to Enhance Audience Connection on Facebook URL @USER #socialmedia #smm URL\n",
            "\n",
            "#BiggBossTamil janani won the task. She is going to first final list👏👏👏👏\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK9YMXntG4p_",
        "outputId": "bd7784d2-cefe-47e9-8e79-66882021754a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/offenseval\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/offenseval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAVp4vfVFZ6W",
        "outputId": "4f90588f-9359-48be-c9ae-e5202d0abb81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Function for emoticon conversion\n",
        "from emoticons import EMOTICONS\n",
        "\n",
        "def convert_emoticons(text):\n",
        "    for emot in EMOTICONS:\n",
        "        text = re.sub(u'('+emot+')', \" \".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
        "    return text\n",
        "\n",
        "\n",
        "#testing the emoticon function\n",
        "text = \"Hello :-) :-)\"\n",
        "text = convert_emoticons(text)\n",
        "print(text + \"\\n\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Happy face smiley Happy face smiley\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdkDKvx9FZ6c",
        "outputId": "65ebbcbe-d62d-4d3f-9baa-181ff6875688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Emoticon conversion\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: convert_emoticons(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**********************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: convert_emoticons(text))\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@USER She should ask a few native Americans what their take on this is.\n",
            "\n",
            "@USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL\n",
            "\n",
            "Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
            "\n",
            "@USER Someone should'veTaken\" this piece of shit to a volcano. 😂\"\n",
            "\n",
            "@USER @USER Obama wanted liberals &amp; illegals to move into red states\n",
            "\n",
            "@USER Liberals are all Kookoo !!!\n",
            "\n",
            "@USER @USER Oh noes! Tough shit.\n",
            "\n",
            "@USER was literally just talking about this Laughing Out Loud all mass shootings like that have been set ups. it’s propaganda used to divide us on major issues like gun control and terrorism\n",
            "\n",
            "@USER Buy more icecream!!!\n",
            "\n",
            "@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo\n",
            "\n",
            "**********************************************************************************\n",
            "#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA Democrats Support Antifa, Muslim Brotherhood, MS13, ISIS, Pedophilia, Child Trafficking, Taxpayer Funded Abortion’s, Election Fraud, Sedition And Treason!!! #LockThemAllUp #WWG1WGA #QAnon ⁦@USER URL\n",
            "\n",
            "#ConstitutionDay is revered by Conservatives, hated by Progressives/Socialist/Democrats that want to change it.\n",
            "\n",
            "#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendment #RNC #USMC #veterans @USER @USER @USER @USER @USER #fakereporting #THESWAMP #dnc #liberals @USER @USER #fakeoutrage @USER First, it reduces the ca URL\n",
            "\n",
            "#Watching #Boomer getting the news that she is still up for parole always makes me smile. #Wentworth Finale...@USER is such a treasure. URL\n",
            "\n",
            "#NoPasaran: Unity demo to oppose the far-right in #London – #antifa #Oct13 — Enough is Enough! URL\n",
            "\n",
            ". . . What the fuck did he do this time?\n",
            "\n",
            "#RAP is a form of ART! Used to express yourself freely. It does not gv the green light or excuse the behavior of acting like an animal! She is not in the streets of the BX where violence is a way of living. Elevate yourself boo and get on @USER level for longevity! #QUEEN👑\n",
            "\n",
            "@USER Do you get the feeling he is kissing @USER behind so he can humiliate him later?\n",
            "\n",
            "5 Tips to Enhance Audience Connection on Facebook URL @USER #socialmedia #smm URL\n",
            "\n",
            "#BiggBossTamil janani won the task. She is going to first final list👏👏👏👏\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19UZfUjlFZ6h",
        "outputId": "2515693e-db36-4277-f31b-a6701c830962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# FUnction for removal of emoji\n",
        "import emoji\n",
        "\n",
        "def convert_emojis(text):\n",
        "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "    text = re.sub(\"_|-\",\" \",text)\n",
        "    return text\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: convert_emojis(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: convert_emojis(text))\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@USER She should ask a few native Americans what their take on this is.\n",
            "\n",
            "@USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020  oncoming fist  United States  oncoming fist  URL\n",
            "\n",
            "Amazon is investigating Chinese employees who are selling internal data to third party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
            "\n",
            "@USER Someone should'veTaken\" this piece of shit to a volcano.  face with tears of joy \"\n",
            "\n",
            "@USER @USER Obama wanted liberals &amp; illegals to move into red states\n",
            "\n",
            "@USER Liberals are all Kookoo !!!\n",
            "\n",
            "@USER @USER Oh noes! Tough shit.\n",
            "\n",
            "@USER was literally just talking about this Laughing Out Loud all mass shootings like that have been set ups. it’s propaganda used to divide us on major issues like gun control and terrorism\n",
            "\n",
            "@USER Buy more icecream!!!\n",
            "\n",
            "@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo\n",
            "\n",
            "**************************************************************************\n",
            "#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA Democrats Support Antifa, Muslim Brotherhood, MS13, ISIS, Pedophilia, Child Trafficking, Taxpayer Funded Abortion’s, Election Fraud, Sedition And Treason!!! #LockThemAllUp #WWG1WGA #QAnon ⁦@USER URL\n",
            "\n",
            "#ConstitutionDay is revered by Conservatives, hated by Progressives/Socialist/Democrats that want to change it.\n",
            "\n",
            "#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendment #RNC #USMC #veterans @USER @USER @USER @USER @USER #fakereporting #THESWAMP #dnc #liberals @USER @USER #fakeoutrage @USER First, it reduces the ca URL\n",
            "\n",
            "#Watching #Boomer getting the news that she is still up for parole always makes me smile. #Wentworth Finale...@USER is such a treasure. URL\n",
            "\n",
            "#NoPasaran: Unity demo to oppose the far right in #London – #antifa #Oct13 — Enough is Enough! URL\n",
            "\n",
            ". . . What the fuck did he do this time?\n",
            "\n",
            "#RAP is a form of ART! Used to express yourself freely. It does not gv the green light or excuse the behavior of acting like an animal! She is not in the streets of the BX where violence is a way of living. Elevate yourself boo and get on @USER level for longevity! #QUEEN crown \n",
            "\n",
            "@USER Do you get the feeling he is kissing @USER behind so he can humiliate him later?\n",
            "\n",
            "5 Tips to Enhance Audience Connection on Facebook URL @USER #socialmedia #smm URL\n",
            "\n",
            "#BiggBossTamil janani won the task. She is going to first final list clapping hands  clapping hands  clapping hands  clapping hands \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn8WX-8FHbjC",
        "outputId": "02d665be-bb72-45e0-c98b-92875c65aa4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZITistjFZ6m",
        "outputId": "ea8be95e-df53-432c-e22c-622e1c4a122c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Ekphrasis pipe for text pre-processing\n",
        "def ekphrasis_pipe(sentence):\n",
        "    cleaned_sentence = \" \".join(text_processor.pre_process_doc(sentence))\n",
        "    return cleaned_sentence\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Training set completed.......\")\n",
        "#Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Test set completed.......\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set completed.......\n",
            "Test set completed.......\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4LXWqIKFZ6q",
        "outputId": "15ca0c12-7199-48a4-a4d3-73df8b447dd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print_text(text_array,0,10)\n",
        "print(\"************************************************************************\")\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<user> she should ask a few native americans what their take on this is .\n",
            "\n",
            "<user> <user> go home you ’ re drunk ! <repeated> <user> <hashtag> maga </hashtag> <hashtag> trump 2020 </hashtag> oncoming fist united states oncoming fist <allcaps> url </allcaps>\n",
            "\n",
            "amazon is investigating chinese employees who are selling internal data to third party sellers looking for an edge in the competitive marketplace . <allcaps> url </allcaps> <hashtag> amazon </hashtag> <hashtag> maga </hashtag> <hashtag> kag </hashtag> <hashtag> china </hashtag> <hashtag> tcot </hashtag>\n",
            "\n",
            "<user> someone should havetaken \" this piece of shit to a volcano . face with tears of joy \"\n",
            "\n",
            "<user> <user> obama wanted liberals & illegals to move into red states\n",
            "\n",
            "<user> liberals are all kookoo ! <repeated>\n",
            "\n",
            "<user> <user> oh noes ! tough shit .\n",
            "\n",
            "<user> was literally just talking about this laughing out loud all mass shootings like that have been set ups . it ’ s propaganda used to divide us on major issues like gun control and terrorism\n",
            "\n",
            "<user> buy more icecream ! <repeated>\n",
            "\n",
            "<user> canada doesn ’ t need another <allcaps> cuck </allcaps> ! we already have enough <hashtag> looney left </hashtag> <hashtag> liberals </hashtag> f**king <censored> up our great country ! <hashtag> qproofs </hashtag> <hashtag> trudeau must go </hashtag>\n",
            "\n",
            "************************************************************************\n",
            "<hashtag> who is q </hashtag> <hashtag> wheres the server </hashtag> <hashtag> dump nike </hashtag> <hashtag> declasfisa </hashtag> democrats support antifa , muslim brotherhood , ms13 , <allcaps> isis </allcaps> , pedophilia , child trafficking , taxpayer funded abortion ’ s , election fraud , sedition and treason ! <repeated> <hashtag> lock them all up </hashtag> <hashtag> wwg 1 wga </hashtag> <hashtag> q anon </hashtag> ⁦ <user> <allcaps> url </allcaps>\n",
            "\n",
            "<hashtag> constitution day </hashtag> is revered by conservatives , hated by progressives / socialist / democrats that want to change it .\n",
            "\n",
            "<hashtag> fox news </hashtag> <hashtag> nra </hashtag> <hashtag> maga </hashtag> <hashtag> potus </hashtag> <hashtag> trump </hashtag> <hashtag> 2 nd amendment </hashtag> <hashtag> rnc </hashtag> <hashtag> usmc </hashtag> <hashtag> veterans </hashtag> <user> <user> <user> <user> <user> <hashtag> fake reporting </hashtag> <hashtag> theswamp </hashtag> <hashtag> dnc </hashtag> <hashtag> liberals </hashtag> <user> <user> <hashtag> fake outrage </hashtag> <user> first , it reduces the ca <allcaps> url </allcaps>\n",
            "\n",
            "<hashtag> watching </hashtag> <hashtag> boomer </hashtag> getting the news that she is still up for parole always makes me smile . <hashtag> wentworth </hashtag> finale . <repeated> <user> is such a treasure . <allcaps> url </allcaps>\n",
            "\n",
            "<hashtag> no pasaran </hashtag> : unity demo to oppose the far right in <hashtag> london </hashtag> – <hashtag> antifa </hashtag> <hashtag> oct 13 </hashtag> — enough is enough ! <allcaps> url </allcaps>\n",
            "\n",
            ". . . what the fuck did he do this time ?\n",
            "\n",
            "<hashtag> rap </hashtag> is a form of <allcaps> art </allcaps> ! used to express yourself freely . it does not gv the green light or excuse the behavior of acting like an animal ! she is not in the streets of the bx where violence is a way of living . elevate yourself boo and get on <user> level for longevity ! <hashtag> queen </hashtag> crown\n",
            "\n",
            "<user> do you get the feeling he is kissing <user> behind so he can humiliate him later ?\n",
            "\n",
            "<number> tips to enhance audience connection on facebook <allcaps> url </allcaps> <user> <hashtag> social media </hashtag> <hashtag> smm </hashtag> <allcaps> url </allcaps>\n",
            "\n",
            "<hashtag> bigg boss tamil </hashtag> janani won the task . she is going to first final list clapping hands clapping hands clapping hands clapping hands\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9WO_7JIFZ6v",
        "outputId": "10d42d45-c1d5-4715-9e72-278bfd1e743b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Removing unnecessary punctuations\n",
        "PUNCT_TO_REMOVE = \"\\\"$%&'()+,-./;=[\\]^_`{|}~\"\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: remove_punctuation(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"********************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_test = text_array_test.apply(lambda text: remove_punctuation(text))\n",
        "print_text(text_array_test,0,10)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<user> she should ask a few native americans what their take on this is \n",
            "\n",
            "<user> <user> go home you ’ re drunk ! <repeated> <user> <hashtag> maga <hashtag> <hashtag> trump 2020 <hashtag> oncoming fist united states oncoming fist <allcaps> url <allcaps>\n",
            "\n",
            "amazon is investigating chinese employees who are selling internal data to third party sellers looking for an edge in the competitive marketplace  <allcaps> url <allcaps> <hashtag> amazon <hashtag> <hashtag> maga <hashtag> <hashtag> kag <hashtag> <hashtag> china <hashtag> <hashtag> tcot <hashtag>\n",
            "\n",
            "<user> someone should havetaken  this piece of shit to a volcano  face with tears of joy \n",
            "\n",
            "<user> <user> obama wanted liberals  illegals to move into red states\n",
            "\n",
            "<user> liberals are all kookoo ! <repeated>\n",
            "\n",
            "<user> <user> oh noes ! tough shit \n",
            "\n",
            "<user> was literally just talking about this laughing out loud all mass shootings like that have been set ups  it ’ s propaganda used to divide us on major issues like gun control and terrorism\n",
            "\n",
            "<user> buy more icecream ! <repeated>\n",
            "\n",
            "<user> canada doesn ’ t need another <allcaps> cuck <allcaps> ! we already have enough <hashtag> looney left <hashtag> <hashtag> liberals <hashtag> f**king <censored> up our great country ! <hashtag> qproofs <hashtag> <hashtag> trudeau must go <hashtag>\n",
            "\n",
            "********************************************************************\n",
            "<hashtag> who is q <hashtag> <hashtag> wheres the server <hashtag> <hashtag> dump nike <hashtag> <hashtag> declasfisa <hashtag> democrats support antifa  muslim brotherhood  ms13  <allcaps> isis <allcaps>  pedophilia  child trafficking  taxpayer funded abortion ’ s  election fraud  sedition and treason ! <repeated> <hashtag> lock them all up <hashtag> <hashtag> wwg 1 wga <hashtag> <hashtag> q anon <hashtag> ⁦ <user> <allcaps> url <allcaps>\n",
            "\n",
            "<hashtag> constitution day <hashtag> is revered by conservatives  hated by progressives  socialist  democrats that want to change it \n",
            "\n",
            "<hashtag> fox news <hashtag> <hashtag> nra <hashtag> <hashtag> maga <hashtag> <hashtag> potus <hashtag> <hashtag> trump <hashtag> <hashtag> 2 nd amendment <hashtag> <hashtag> rnc <hashtag> <hashtag> usmc <hashtag> <hashtag> veterans <hashtag> <user> <user> <user> <user> <user> <hashtag> fake reporting <hashtag> <hashtag> theswamp <hashtag> <hashtag> dnc <hashtag> <hashtag> liberals <hashtag> <user> <user> <hashtag> fake outrage <hashtag> <user> first  it reduces the ca <allcaps> url <allcaps>\n",
            "\n",
            "<hashtag> watching <hashtag> <hashtag> boomer <hashtag> getting the news that she is still up for parole always makes me smile  <hashtag> wentworth <hashtag> finale  <repeated> <user> is such a treasure  <allcaps> url <allcaps>\n",
            "\n",
            "<hashtag> no pasaran <hashtag> : unity demo to oppose the far right in <hashtag> london <hashtag> – <hashtag> antifa <hashtag> <hashtag> oct 13 <hashtag> — enough is enough ! <allcaps> url <allcaps>\n",
            "\n",
            "   what the fuck did he do this time ?\n",
            "\n",
            "<hashtag> rap <hashtag> is a form of <allcaps> art <allcaps> ! used to express yourself freely  it does not gv the green light or excuse the behavior of acting like an animal ! she is not in the streets of the bx where violence is a way of living  elevate yourself boo and get on <user> level for longevity ! <hashtag> queen <hashtag> crown\n",
            "\n",
            "<user> do you get the feeling he is kissing <user> behind so he can humiliate him later ?\n",
            "\n",
            "<number> tips to enhance audience connection on facebook <allcaps> url <allcaps> <user> <hashtag> social media <hashtag> <hashtag> smm <hashtag> <allcaps> url <allcaps>\n",
            "\n",
            "<hashtag> bigg boss tamil <hashtag> janani won the task  she is going to first final list clapping hands clapping hands clapping hands clapping hands\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQmxE8_s1Bbk",
        "outputId": "28be2645-76d5-44a5-8366-f31167f35b20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# print_text(text_array,3550,3555)\n",
        "print_text(original,9540,9555)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@USER i think its because he is remaining this pure sweet thing\n",
            "\n",
            "@USER @USER You think they’ll “get” violent? Antifa already is..... I do agree it will get worse.  That’s why we all need to learn self defense and get concealed carry approved w/insurance.\n",
            "\n",
            "@USER So what ur saying is that it is in fact chicken shit and you are eating chicken shit URL\n",
            "\n",
            "@USER I blame @USER for inciting violence and she should be held accountable! She is a despicable disgrace.\n",
            "\n",
            "@USER @USER My sister is in G’ville. Says she is going to text you\n",
            "\n",
            "@USER Here she is........ URL\n",
            "\n",
            "@USER Liberals with their lies again.\n",
            "\n",
            "@USER Police state tyrant liberals LOVE the word dangerous\" when gaslighting their sheep.\"\n",
            "\n",
            "@USER @USER @USER @USER It to t dd\n",
            "\n",
            "@USER @USER @USER @USER Obama will be remembered as the man that destroy libya. Imagine if mi6 or cia give blm or antifa guns and wages war vs trump. Then they control the msm and say trump use chemical weapon to legalize their coup. The blood is on obama hand.\n",
            "\n",
            "@USER @USER I apologize if you inferred I was calling you Antifa. I was qualifying one of my many reasons for owning an arsenal.\n",
            "\n",
            "@USER I think he WAS black. But thank God the police here behaved professionally. She is SCARY!\n",
            "\n",
            "@USER @USER @USER Arms\" WERE/ARE TO BE REGULATED BY LAW—those regulations aimed at near-universal armament/training with contemporary military grade design \"Arms\" personally owned/possessed &amp; kept in the HOME—by \"the people\" #2A that is CONSTITUTIONAL \"gun control\".\"\n",
            "\n",
            "@USER @USER lmao @ the WORLD league viewership compared to league of legends or overwatch or cs:go. Main issues are that the format is shit and the game is on console. So you need to fix one of them. Console could be turned into an advantage uf u capture the attention of Joe Shmo\n",
            "\n",
            "@USER @USER He is past his sell-by date.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsNw3V7MFZ62",
        "outputId": "7665f4db-1f78-4e08-b120-8218d2ae9552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Finding length of longest array\n",
        "maxLen = len(max(text_array,key = lambda text: len(text.split(\" \"))).split(\" \"))\n",
        "print(maxLen)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXlK2jraFZ68",
        "outputId": "f1dee5c5-5f21-4053-9898-c082b2360392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "u = lambda text: len(text.split(\" \"))\n",
        "sentence_lengths = []\n",
        "for x in text_array:\n",
        "    sentence_lengths.append(u(x))\n",
        "print(sorted(sentence_lengths)[-100:])\n",
        "print(len(sentence_lengths))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 84, 84, 84, 84, 85, 85, 85, 85, 85, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 87, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 90, 91, 91, 91, 91, 92, 92, 92, 92, 92, 93, 93, 93, 93, 94, 94, 94, 95, 95, 96, 96, 97, 97, 97, 98, 99, 100, 100, 100, 101, 101, 102, 103, 103, 103, 104, 105, 107, 108, 108, 109, 109, 111, 111, 112, 115, 116, 117, 119, 159]\n",
            "13240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q94LkYyFZ7A"
      },
      "source": [
        "<h2>Text pre-processing complete</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6iCqNnyFZ7X",
        "outputId": "0b0e0b7b-053c-4a9d-b5fe-99c851a90156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Count of each label in dataset\n",
        "from collections import Counter\n",
        "\n",
        "# Printing training set counts for analysis\n",
        "print(\"Elements: \",set(labels))\n",
        "print(\"Length: \",len(labels))\n",
        "print(Counter(labels))\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Printing validation set counts for analysis\n",
        "print(\"Elements: \",set(labels_test))\n",
        "print(\"Length: \",len(labels_test))\n",
        "print(Counter(labels_test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements:  {'NOT', 'OFF'}\n",
            "Length:  13240\n",
            "Counter({'NOT': 8840, 'OFF': 4400})\n",
            "**************************************************************************\n",
            "Elements:  {'NOT', 'OFF'}\n",
            "Length:  860\n",
            "Counter({'NOT': 620, 'OFF': 240})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "005HnK3xFZ7b"
      },
      "source": [
        "Y = []\n",
        "Y_test = []\n",
        "\n",
        "# Training set\n",
        "for i in range(0,len(labels)):\n",
        "    if(labels[i] == \"OFF\"):\n",
        "        Y.append(0)\n",
        "    if(labels[i] == \"NOT\"):\n",
        "        Y.append(1)\n",
        "\n",
        "# Validation set\n",
        "for i in range(0,len(labels_test)):\n",
        "    if(labels_test[i] == \"OFF\"):\n",
        "        Y_test.append(0)\n",
        "    if(labels_test[i] == \"NOT\"):\n",
        "        Y_test.append(1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGOgKNrEBqXs"
      },
      "source": [
        "Y_target = []\n",
        "Y_target_test = []\n",
        "\n",
        "# Training set\n",
        "for i in range(0,len(labels_target)):\n",
        "    if(labels_target[i] == \"NA\"):\n",
        "        Y_target.append(0)\n",
        "    if(labels_target[i] == \"TIN\"):\n",
        "        Y_target.append(1)\n",
        "    if(labels_target[i] == \"UNT\"):\n",
        "        Y_target.append(2)\n",
        "\n",
        "# Validation set\n",
        "for i in range(0,len(labels_target_test)):\n",
        "    if(labels_target_test[i] == \"NA\"):\n",
        "        Y_target_test.append(0)\n",
        "    if(labels_target_test[i] == \"TIN\"):\n",
        "        Y_target_test.append(1)\n",
        "    if(labels_target_test[i] == \"UNT\"):\n",
        "        Y_target_test.append(2)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXy6Wxh2FZ7f",
        "outputId": "1a55b707-65ba-4ad5-b504-176ca7508bfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Testing the conversion into integers\n",
        "for i in range(200,210):\n",
        "    print(text_array_test[i])\n",
        "    print(labels_test[i],Y_test[i])\n",
        "    print(labels_target_test[i],Y_target_test[i])\n",
        "    print()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<hashtag> antifa <hashtag> demo in memory of <hashtag> killah p <hashtag>  <hashtag> greece <hashtag> <allcaps> url <allcaps>\n",
            "NOT 1\n",
            "NA 0\n",
            "\n",
            "<user> these are all coranated attacks from idiot loons ! they will get worse much worse before the election ! can you imagine idiots who want to get rid of the economy and their <number> along with interest rates just because he is not a polished politician ? idiots !\n",
            "OFF 0\n",
            "TIN 1\n",
            "\n",
            "<user> <user> a <elongated> she is so stinking cute ! how old is she now ?\n",
            "OFF 0\n",
            "TIN 1\n",
            "\n",
            "<hashtag> benghazi <hashtag> <hashtag> haiti <hashtag> <hashtag> uranium one <hashtag> <hashtag> seth rich <hashtag> what more does the justice department need ? no double standards ! just because you are rich and powerful does not mean you can rob  seal and murder ! <hashtag> drain the swamp <hashtag> <hashtag> hillary for prison <hashtag> <hashtag> vote red <hashtag> <hashtag> maga <hashtag> <allcaps> url <allcaps>\n",
            "OFF 0\n",
            "UNT 2\n",
            "\n",
            "<hashtag> black <hashtag> eyed peas tackle gun control  social justice on new song ‘ big love ’ : single highlights group  s first album in eight years   masters of the sun  <allcaps> url url <allcaps>\n",
            "NOT 1\n",
            "NA 0\n",
            "\n",
            "<hashtag> censorship <hashtag> awake yet ? ask yourself why these conservatives are being censored ? <hashtag> walk away <hashtag> <allcaps> url <allcaps>\n",
            "NOT 1\n",
            "NA 0\n",
            "\n",
            "you didnt have to beat him up like that  <repeated> all he said was you are looking so delicious   you say as you clean up his bruised knuckles   nobody talks to my woman that way  <repeated> except me   he pulls you on to his lap   do you want me to kiss it and make it feel better ?  you tease   <allcaps> url <allcaps>\n",
            "NOT 1\n",
            "NA 0\n",
            "\n",
            "<hashtag> join the fight <hashtag> join the fight against american communists  <repeated> democrats and liberals have taken this crap to the edge and there is no coming back  they are openly promoting the destruction of <allcaps> america <allcaps>  <hashtag> join the fight against communism <hashtag> <allcaps> url <allcaps>\n",
            "OFF 0\n",
            "TIN 1\n",
            "\n",
            "<hashtag> art <hashtag> <hashtag> artists on twitter <hashtag> <hashtag> soul <hashtag> <hashtag> good business <hashtag> <hashtag> entrepreneur <hashtag> <hashtag> success <hashtag> <hashtag> excellence <hashtag> <hashtag> woman in business <hashtag> <hashtag> mind blowing <hashtag> <hashtag> quotestoliveby <hashtag> “ be gentle with yourself  you are a child of the universe no less than the trees and the stars  you have a right to be here  ” by max ehrmann <allcaps> url <allcaps>\n",
            "NOT 1\n",
            "NA 0\n",
            "\n",
            "<hashtag> icymi <hashtag> : welcome anna grey barbour to our women ’ s volleyball team ! anna is a <number> terry sanford high school graduate  she is studying dental hygiene at our college  we ’ re proud to make you a trojan  anna  good luck this season ! <hashtag> black n gold <hashtag> <hashtag> trojans <hashtag> volleyball black heart yellow heart <allcaps> url <allcaps>\n",
            "NOT 1\n",
            "NA 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-95uJgsFZ7k",
        "outputId": "42b78516-f07c-49ee-968f-47d73a8ea679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Verifying train set\n",
        "X = np.asarray(list(text_array))\n",
        "Y = np.asarray(list(Y))\n",
        "Y_target = np.asarray(list(Y_target))\n",
        "print(type(X))\n",
        "print(type(Y))\n",
        "print(type(Y_target))\n",
        "print(np.shape(X),np.shape(Y),np.shape(Y_target))\n",
        "\n",
        "# Verifying validation set\n",
        "X_test = np.asarray(list(text_array_test))\n",
        "Y_test = np.asarray(list(Y_test))\n",
        "Y_target_test = np.asarray(list(Y_target_test))\n",
        "print(type(X_test))\n",
        "print(type(Y_test))\n",
        "print(type(Y_target_test))\n",
        "print(np.shape(X_test),np.shape(Y_test),np.shape(Y_target_test))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(13240,) (13240,) (13240,)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(860,) (860,) (860,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se9u5rOU4DTf",
        "outputId": "27bbf768-f405-4cd5-e300-4eca10ad9f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(Counter(Y))\n",
        "print(Counter(Y_test))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({np.int64(1): 8840, np.int64(0): 4400})\n",
            "Counter({np.int64(1): 620, np.int64(0): 240})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRqxpkqDnRrY",
        "outputId": "d5451d33-1537-4c28-9c17-4c6e71421790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_test[0])\n",
        "print(Y_test[0])\n",
        "print(labels_test[0])\n",
        "print(Y_target_test[0])\n",
        "print(labels_target_test[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<hashtag> who is q <hashtag> <hashtag> wheres the server <hashtag> <hashtag> dump nike <hashtag> <hashtag> declasfisa <hashtag> democrats support antifa  muslim brotherhood  ms13  <allcaps> isis <allcaps>  pedophilia  child trafficking  taxpayer funded abortion ’ s  election fraud  sedition and treason ! <repeated> <hashtag> lock them all up <hashtag> <hashtag> wwg 1 wga <hashtag> <hashtag> q anon <hashtag> ⁦ <user> <allcaps> url <allcaps>\n",
            "0\n",
            "OFF\n",
            "1\n",
            "TIN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZvFBMRRFZ7p"
      },
      "source": [
        "<h2>Shuffling training and validation data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9P3ZmhZFZ7r"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6-U6ElWFZ7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65237f91-0ffc-488b-b3e9-07b252ee4eb4"
      },
      "source": [
        "print(Counter(labels))\n",
        "print(Counter(labels_test))\n",
        "print(Counter(labels_target))\n",
        "print(Counter(labels_target_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'NOT': 8840, 'OFF': 4400})\n",
            "Counter({'NOT': 620, 'OFF': 240})\n",
            "Counter({'NA': 8840, 'TIN': 3876, 'UNT': 524})\n",
            "Counter({'NA': 620, 'TIN': 213, 'UNT': 27})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EQXXOb-FZ73"
      },
      "source": [
        "# Converting to one hot vectors\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)] #u[Y] helps to index each element of Y index at u. U here is a class array\n",
        "    return Y"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WydeObXQFZ77",
        "outputId": "cd73a919-97d8-46a3-8492-5e25419daf86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y_oh_train = convert_to_one_hot(np.array(Y), C = 2)\n",
        "Y_oh_test = convert_to_one_hot(np.array(Y_test), C = 2)\n",
        "\n",
        "Y_oh_target_train = convert_to_one_hot(np.array(Y_target), C = 3)\n",
        "Y_oh_target_test = convert_to_one_hot(np.array(Y_target_test), C = 3)\n",
        "print(np.shape(Y_oh_train))\n",
        "print(np.shape(Y_oh_target_test))\n",
        "index = 0\n",
        "print(labels[index], Y[index], \"is converted into one hot\", Y_oh_train[index])\n",
        "print(labels_target[index], Y_target[index], \"is converted into one hot\", Y_oh_target_train[index])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13240, 2)\n",
            "(860, 3)\n",
            "OFF 0 is converted into one hot [1. 0.]\n",
            "UNT 2 is converted into one hot [0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk9YydcsFZ8C"
      },
      "source": [
        "<h2>Model using RoBERTa</h2>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "id": "Q_RY_pHc1BEN",
        "outputId": "4ec9561e-9887-4080-caf3-92b89ba8b607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Lxn5eGvDAE"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import os\n",
        "from collections import Counter"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tf-keras"
      ],
      "metadata": {
        "id": "f9J4FpDz1dNp",
        "outputId": "b1031975-ae51-410d-d53c-462366b27c84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf-keras) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w35qjBz-vEo3"
      },
      "source": [
        "from transformers import RobertaTokenizerFast, TFRobertaModel, TFBertModel, BertTokenizerFast, ElectraTokenizerFast, TFElectraModel, AlbertTokenizerFast, TFAlbertModel, XLNetTokenizerFast, TFXLNetModel, MPNetTokenizerFast, TFMPNetModel\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import RepeatVector, Concatenate, Dense, Activation, Dot, BatchNormalization, Dropout\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d97gRRE9y383",
        "outputId": "4e4253ce-2a74-4ef0-cae4-4adbe4f01a54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSTFXg6DYo8O",
        "outputId": "09c68ece-4f35-411d-89f8-a7db001d6c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"✅ GPU is available and ready to use.\")\n",
        "    print(tf.config.list_physical_devices('GPU'))\n",
        "else:\n",
        "    print(\"❌ GPU not detected. Please recheck runtime settings.\")\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GPU is available and ready to use.\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Za2kQSGvVWI",
        "outputId": "b45dab6d-ee80-473c-fe61-2b0f8d16e483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "acf39ad219de4d729f4c71ac5deaae79",
            "5759f89f03b245a3bfe7228b221c933b",
            "eb2917c7bea546bfab4ae7867a636aac",
            "f9b90f1432d244f1ae650acbf6ca6723",
            "0dd6707e7a7b49c7944509db76043ab6",
            "dbc7817ba3e845dd87e86ea59c3ac604",
            "ae8081b451114012a3c378d1340603ea",
            "4e95c954dc1b4dcaa02f7f6266f3f35c",
            "d0c8a0a67e1643b2a7136f5d99757eec",
            "4417690250ca47b29f9c8249beaba424",
            "a4fc7b8c7356400183412b2cfc7a6702",
            "ed3a5362c51148e0bb4132ade646c96f",
            "a242b6b9f29b476ea87c98628cfb22a6",
            "67fc694248ba428aba99f6dd5077ffa1",
            "5518f2781dbd4f34ab7ab40d612496a6",
            "a318714be08541c6b1c894c8db3469ca",
            "7f21a65a8bcf40c7ad11ca36f2421681",
            "7a587973ad6a407c8934f94b44b8943b",
            "b0491c94154e4538838479692484d7d4",
            "1d4a430b61d9423186d817219ad7fcd6",
            "9bcb1a8a75a34b32a13bdc2bb7aa3c2e",
            "d16080723fea42a9a5a72f9c847c1d76",
            "8416e009706c480b90cb61b9d6eeacd8",
            "648959b54a284b52b483c97b9923dae6",
            "c3e4a359c24846be9d0a24bcb7c8e2ff",
            "81f19325ba8648e2a46b822d9621acad",
            "a0f7803244b74c788c6e08eed2ce1a0d",
            "a80ebe69d60d4c0ca8b6dc082dfbad1a",
            "21eb300959dc4fd58ed746dfef69b01c",
            "529bd20738074a9b8423c60d60abfb12",
            "65fcb3652fa2466d81539303d26f8c98",
            "9ca5c125875e4bfd86cc1abeb51d4087",
            "b79dd290afe242a2aa77680eee01d92e",
            "c06d459ba2b84a05a33f5fb754b9ec94",
            "e4fbfe7b525c4e0aa7b45e90a84c8533",
            "8ba2bc9043804a7fa364726100bb8d90",
            "7aae70d0a9704272a0672104dd1a9dd5",
            "b58eaae58ade45899599b5afd527e1e5",
            "1bda443c6722422392b0559d8456375b",
            "b856c65ed71c495e9e17e0e13859921e",
            "46ca5d37537c433187707531803a2672",
            "9265634e0f8448408751a12aeb226756",
            "efd3a2ba4e244ebd8e7a0fac6c996ac1",
            "424d36ad141343979bd93749e2f798f4",
            "f4026f511f684a45b176e99dd6bf6646",
            "9ca175a4b7184778b8d7adf4f8152865",
            "4a1db13761c244739ccc64a5c45344e5",
            "5102be6473b14e1e94817d331dabeb08",
            "36846505eff3426291d5974b1df58438",
            "15f794688d064884ba7a955ff96ede55",
            "85af9b4f07044edba0d76f5effbc7450",
            "d1e6193911394576a52994245fd1f30c",
            "60ab6cf3a10f422c95b9172b0af7ebb9",
            "5b04e184e11e403ca9f40760d2f04694",
            "3f7862773fc542f79ccdc00bd1ba590a"
          ]
        }
      },
      "source": [
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acf39ad219de4d729f4c71ac5deaae79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed3a5362c51148e0bb4132ade646c96f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8416e009706c480b90cb61b9d6eeacd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c06d459ba2b84a05a33f5fb754b9ec94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4026f511f684a45b176e99dd6bf6646"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL_GaDaavdNk"
      },
      "source": [
        "X = list(X)\n",
        "X_test = list(X_test)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2vEqLJDzNnE"
      },
      "source": [
        "model_train_x, model_val_x, Y_train, Y_val = train_test_split(X, Y, test_size=0.05, random_state=44)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce2tYBEpvdJo"
      },
      "source": [
        "train_encodings = tokenizer(model_train_x, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')\n",
        "val_encodings = tokenizer(model_val_x, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')\n",
        "test_encodings = tokenizer(X_test, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE2O9UySazhE"
      },
      "source": [
        "cluster_encodings = tokenizer(X, max_length=100, truncation=True, padding=\"max_length\", return_tensors='tf')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0VMHbInvcVi",
        "outputId": "a2fb3ccb-90df-41ee-cca7-e74cfb893354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(np.shape(train_encodings[\"input_ids\"]))\n",
        "print(np.shape(val_encodings[\"input_ids\"]))\n",
        "print(np.shape(test_encodings[\"input_ids\"]))\n",
        "print(np.shape(cluster_encodings[\"input_ids\"]))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12578, 100)\n",
            "(662, 100)\n",
            "(860, 100)\n",
            "(13240, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYs7gYzsvcOa",
        "outputId": "4df608dd-ee92-4695-be5a-055f48de49c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_encodings[\"input_ids\"][0])\n",
        "print(\"***************************************************************************\")\n",
        "print(val_encodings[\"input_ids\"][0])\n",
        "print(\"***************************************************************************\")\n",
        "print(test_encodings[\"input_ids\"][0])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[    0 41552 12105 15698 28696 12105 15698    79  7533  6245  3867    63\n",
            "     7   492    10 18066   995     7   120   658    50  9876 15247    24\n",
            "  1302  1437     2     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1], shape=(100,), dtype=int32)\n",
            "***************************************************************************\n",
            "tf.Tensor(\n",
            "[    0 41552 12105 15698 28696 12105 15698    47  2369   101     5 28696\n",
            "  1250 25879 15698   295   763 28696  1250 25879 15698   584    24    44\n",
            "    27   579   350  1010     7  1067    59  1751   797  1437   114    51\n",
            "    58   593     7   512    25    47   224    51    74    33   450     5\n",
            "   228   642  1437   912   442 19791  1437     5 28696  1250 25879 15698\n",
            "   920 28696  1250 25879 15698    16     5  1802   259  1437   114    89\n",
            "    32   181  2911    54   218    44    27   326   216    93  1041  4832\n",
            " 28696  1250 25879 15698   393 28696  1250 25879 15698   989 11540   920\n",
            " 23983  6228    11     2], shape=(100,), dtype=int32)\n",
            "***************************************************************************\n",
            "tf.Tensor(\n",
            "[    0 41552 25903 10058 15698    54    16  2231 28696 25903 10058 15698\n",
            " 28696 25903 10058 15698 33116  1535     5 10228 28696 25903 10058 15698\n",
            " 28696 25903 10058 15698 12371   295  4348 28696 25903 10058 15698 28696\n",
            " 25903 10058 15698 16163   281   506  6619 28696 25903 10058 15698 38538\n",
            "  2923   323  9876 15247  1437 11721 10839  2138  8489  1437 43601  1558\n",
            "  1437 28696  1250 25879 15698    16   354 28696  1250 25879 15698  1437\n",
            " 32310 10990  1437   920  7492  1437 11827  6140  6428    44    27   579\n",
            "  1437   729  3526  1437 10195  7469     8 27470 27785 28696 36456  1070\n",
            " 15698 28696 25903     2], shape=(100,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdKykEUBmu5M"
      },
      "source": [
        "<h3> Subtask A</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRJHpbxaFZ86"
      },
      "source": [
        "def Offense_classifier(input_shape):\n",
        "    \"\"\"\n",
        "    Function creating the model's graph.\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the input,(max_len,)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 100-dimensional vector representation\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (13 million words)\n",
        "\n",
        "    Returns:\n",
        "    model -- a model instance in Keras\n",
        "    \"\"\"\n",
        "    model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "    layer = model.layers[0]\n",
        "\n",
        "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
        "    inputs = keras.Input(shape=input_shape, dtype='int32')\n",
        "    input_masks = keras.Input(shape=input_shape, dtype='int32')\n",
        "\n",
        "    embeddings = layer([inputs, input_masks])[1]\n",
        "\n",
        "    X = BatchNormalization(momentum=0.99, epsilon=0.001, center=True, scale=True)(embeddings)\n",
        "\n",
        "    # Add dropout with a probability of 0.1\n",
        "    X = Dropout(0.1)(X)\n",
        "\n",
        "    X = Dense(128,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = Dense(32,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = Dense(3,activation='elu',kernel_regularizer=keras.regularizers.l2(0.01))(X)\n",
        "\n",
        "    X = Dense(32,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = BatchNormalization(momentum=0.99, epsilon=0.001, center=True, scale=True)(X)\n",
        "\n",
        "    X = Dense(128,activation='elu',kernel_regularizer=keras.regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = Dense(1,activation='linear',kernel_regularizer=keras.regularizers.l2(0.01))(X)\n",
        "\n",
        "    # Add a sigmoid activation\n",
        "    X = Activation('sigmoid')(X)\n",
        "\n",
        "    # Create Model instance which converts sentence_indices into X.\n",
        "    model = keras.Model(inputs=[inputs,input_masks], outputs=[X])\n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from transformers import TFRobertaModel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def Offense_classifier(input_shape):\n",
        "    \"\"\"\n",
        "    Function creating the model's graph.\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the input,(max_len,)\n",
        "\n",
        "    Returns:\n",
        "    model -- a model instance in Keras\n",
        "    \"\"\"\n",
        "    model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "    layer = model.layers[0]\n",
        "\n",
        "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
        "    inputs = tf.keras.Input(shape=input_shape, dtype='int32')\n",
        "    input_masks = tf.keras.Input(shape=input_shape, dtype='int32')\n",
        "\n",
        "    embeddings = layer([inputs, input_masks])[1]\n",
        "\n",
        "    X = layers.BatchNormalization(momentum=0.99, epsilon=0.001, center=True, scale=True)(embeddings)\n",
        "\n",
        "    # Add dropout with a probability of 0.1\n",
        "    X = layers.Dropout(0.1)(X)\n",
        "\n",
        "    X = layers.Dense(128, activation='elu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = layers.Dense(32, activation='elu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = layers.Dense(3, activation='elu', kernel_regularizer=regularizers.l2(0.01))(X)\n",
        "\n",
        "    X = layers.Dense(32, activation='elu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = layers.BatchNormalization(momentum=0.99, epsilon=0.001, center=True, scale=True)(X)\n",
        "\n",
        "    X = layers.Dense(128, activation='elu', kernel_regularizer=regularizers.l2(0.001))(X)\n",
        "\n",
        "    X = layers.Dense(1, activation='linear', kernel_regularizer=regularizers.l2(0.01))(X)\n",
        "\n",
        "    # Add a sigmoid activation\n",
        "    X = layers.Activation('sigmoid')(X)\n",
        "\n",
        "    # Create Model instance which converts sentence_indices into X.\n",
        "    model = tf.keras.Model(inputs=[inputs, input_masks], outputs=[X])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "KPHJ7NZo4xON"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoCY8kjG0DC5",
        "outputId": "74b4d0df-e02c-410c-ab19-0023c002a8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'resolver' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-fd1a4489033a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'resolver' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLnuscUj0IjO"
      },
      "source": [
        "class EvaluationMetric(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, trial_encodings, trial_masks, Y_test):\n",
        "        super(EvaluationMetric, self).__init__()\n",
        "        self.trial_encodings = trial_encodings\n",
        "        self.trial_masks = trial_masks\n",
        "        self.Y_test = Y_test\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        print(\"\\nTraining...\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        print(\"\\nEvaluating...\")\n",
        "        trial_prediction = self.model.predict([self.trial_encodings,self.trial_masks])\n",
        "\n",
        "        pred = []\n",
        "        for i in range(0,len(self.Y_test)):\n",
        "            num = trial_prediction[i]\n",
        "            if(num > 0.5):\n",
        "              num = 1\n",
        "            else:\n",
        "              num = 0\n",
        "            pred.append(num)\n",
        "\n",
        "        from sklearn.metrics import classification_report\n",
        "        print(classification_report(Y_test, pred, digits=3))\n",
        "\n",
        "evaluation_metric = EvaluationMetric(test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"], Y_test)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCOUVfDy0IYr",
        "outputId": "9842748e-70fa-4a15-9aa5-94e19448f2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "with strategy.scope():\n",
        "    model = Offense_classifier((100,))\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=2e-5)\n",
        "    loss_fun = [\n",
        "          tf.keras.losses.BinaryCrossentropy()\n",
        "    ]\n",
        "    metric = ['acc']\n",
        "    model.compile(optimizer=optimizer, loss=loss_fun, metrics=metric)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'strategy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-7f2e4b2b1cca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOffense_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     loss_fun = [\n\u001b[1;32m      5\u001b[0m           \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQdfWk222Act",
        "outputId": "acd7ad38-e8c0-47f2-9d33-8da58d8aeeaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-5f15418b3570>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM223PhsK5Ir",
        "outputId": "4f307042-e857-4a5d-cd81-6499777486bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "neg, pos = np.bincount(Y)\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples:\n",
            "    Total: 13240\n",
            "    Positive: 8840 (66.77% of total)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCtur56mLoep",
        "outputId": "e5ed2c74-2ece-4954-e03c-4391cf015fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class_weight = {}\n",
        "maxi = max(neg, pos)\n",
        "weight_for_0 = (maxi / (maxi + neg))\n",
        "weight_for_1 = (maxi / (maxi + pos))\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight for class 0: 0.67\n",
            "Weight for class 1: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mEBrm9NFZ9W",
        "outputId": "a1cdf541-e1f3-464e-979a-3029e1a0d3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(filepath='/content/olid_roberta.{epoch:03d}.h5',\n",
        "                                 monitor='val_acc',\n",
        "                                 verbose=1,\n",
        "                                 save_weights_only=True,\n",
        "                                 period=1)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ModelCheckpoint.__init__() got an unexpected keyword argument 'period'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-01c5711ff47d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m checkpoint = ModelCheckpoint(filepath='/content/olid_roberta.{epoch:03d}.h5',\n\u001b[0m\u001b[1;32m      3\u001b[0m                                  \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                  \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ModelCheckpoint.__init__() got an unexpected keyword argument 'period'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5OEmpHyzDQ-"
      },
      "source": [
        "print(Counter(Y))\n",
        "print(Counter(Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Ejap9-cMoj"
      },
      "source": [
        "print(Counter(Y_train))\n",
        "print(Counter(Y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Otd9w3JbVbq"
      },
      "source": [
        "print(len(train_encodings[\"input_ids\"]),len(val_encodings[\"input_ids\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCKlwagz6j31"
      },
      "source": [
        "# val 0.05\n",
        "history = model.fit(\n",
        "    x = [train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"]],\n",
        "    y = Y_train,\n",
        "    validation_data = ([val_encodings[\"input_ids\"],val_encodings[\"attention_mask\"]],Y_val),\n",
        "    callbacks = [evaluation_metric, checkpoint],\n",
        "    batch_size = 64,\n",
        "    shuffle=True,\n",
        "    epochs=6,\n",
        "    class_weight = class_weight\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = np.array(input_ids)  # Shape should be (num_samples, max_length)\n",
        "attention_masks = np.array(attention_masks)  # Shape should be (num_samples, max_length)\n",
        "labels = np.array(labels)  # Shape should be (num_samples,)\n",
        "\n",
        "# Now check shapes\n",
        "print(f\"input_ids shape: {input_ids.shape}\")\n",
        "print(f\"attention_masks shape: {attention_masks.shape}\")\n",
        "print(f\"labels shape: {labels.shape}\")\n",
        "\n",
        "# Ensure they all match, then fit the model\n",
        "model.fit([input_ids, attention_masks], labels, epochs=3, batch_size=32)\n"
      ],
      "metadata": {
        "id": "Rw3Yq85T465F",
        "outputId": "c020d7c6-d467-4420-8e8d-27b38d757d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids shape: (2, 8)\n",
            "attention_masks shape: (2, 8)\n",
            "labels shape: (13240,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data cardinality is ambiguous:\n  x sizes: 2, 2\n  y sizes: 13240\nMake sure all arrays contain the same number of samples.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-249f95f21706>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Ensure they all match, then fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1957\u001b[0m             )\n\u001b[1;32m   1958\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 2, 2\n  y sizes: 13240\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer\n",
        "import numpy as np\n",
        "\n",
        "# Load the tokenizer for RoBERTa\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "# Example texts (this should be replaced with your actual dataset)\n",
        "texts = [\"This is a sample sentence.\"] * 13240  # Replace with your actual data\n",
        "\n",
        "# Tokenize the texts with padding and truncation to max length of 128\n",
        "inputs = tokenizer(texts, padding='max_length', truncation=True, max_length=128, return_tensors='np')\n",
        "\n",
        "# Extract tokenized inputs\n",
        "input_ids = inputs['input_ids']\n",
        "attention_masks = inputs['attention_mask']\n",
        "\n",
        "# Verify the shapes of the tokenized inputs\n",
        "print(f\"input_ids shape: {input_ids.shape}\")  # Should print (13240, 128)\n",
        "print(f\"attention_masks shape: {attention_masks.shape}\")  # Should print (13240, 128)\n",
        "\n",
        "# Labels for training (assuming binary classification task)\n",
        "labels = np.random.randint(0, 2, size=(13240,))\n",
        "\n",
        "# Verify labels shape\n",
        "print(f\"labels shape: {labels.shape}\")  # Should print (13240,)\n",
        "\n",
        "# Define your model (ensure the input shape matches)\n",
        "model = Offense_classifier(input_shape=(128,))  # Ensure the sequence length matches\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit([input_ids, attention_masks], labels, epochs=3, batch_size=32)\n"
      ],
      "metadata": {
        "id": "8Q8b2QdZ4azK",
        "outputId": "eb9678bc-d6c1-47b4-b270-43eac400cddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids shape: (13240, 128)\n",
            "attention_masks shape: (13240, 128)\n",
            "labels shape: (13240,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_30), but are not present in its tracked objects:   <tf.Variable 'dense_37/bias:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_31), but are not present in its tracked objects:   <tf.Variable 'dense_38/bias:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_32), but are not present in its tracked objects:   <tf.Variable 'dense_39/bias:0' shape=(3,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_33), but are not present in its tracked objects:   <tf.Variable 'dense_40/bias:0' shape=(32,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add_34), but are not present in its tracked objects:   <tf.Variable 'dense_41/bias:0' shape=(128,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.add_6), but are not present in its tracked objects:   <tf.Variable 'dense_42/bias:0' shape=(1,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "414/414 [==============================] - 372s 794ms/step - loss: 0.6936 - accuracy: 0.4997\n",
            "Epoch 2/3\n",
            "414/414 [==============================] - 327s 790ms/step - loss: 0.6936 - accuracy: 0.4997\n",
            "Epoch 3/3\n",
            "414/414 [==============================] - 328s 792ms/step - loss: 0.6936 - accuracy: 0.4997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7e05baf7ae90>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "label_map = {'not sexist': 0, 'sexist': 1}\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "val_df = pd.read_csv(\"validate.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Assuming the text is in 'text' and label in 'label_sexist'\n",
        "train_texts, train_labels = train_df['text'].tolist(), train_df['label_sexist'].map(label_map).values\n",
        "val_texts, val_labels = val_df['text'].tolist(), val_df['label_sexist'].map(label_map).values\n",
        "test_texts, test_labels = test_df['text'].tolist(), test_df['label_sexist'].map(label_map).values\n"
      ],
      "metadata": {
        "id": "iJ62eIzNAHek"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(\n",
        "        texts, padding='max_length', truncation=True, max_length=128, return_tensors=\"tf\"\n",
        "    )\n",
        "\n",
        "train_encodings = tokenize_data(train_texts)\n",
        "val_encodings = tokenize_data(val_texts)\n",
        "test_encodings = tokenize_data(test_texts)\n"
      ],
      "metadata": {
        "id": "fUDElaJWB_W1",
        "outputId": "39d0ef19-204b-40e8-fd43-af1829b7cab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original test_labels:\", test_labels[:10])\n",
        "\n"
      ],
      "metadata": {
        "id": "DA7SYF7sew9o",
        "outputId": "49f1d37d-4854-4a0a-bc30-c335f5ea6d5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original test_labels: [0 1 0 1 1 0 0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import TFRobertaModel\n",
        "\n",
        "# Load model once\n",
        "roberta = TFRobertaModel.from_pretrained('roberta-base')\n",
        "\n",
        "def extract_features(encodings, batch_size=32):\n",
        "    input_ids = encodings['input_ids']\n",
        "    attention_mask = encodings['attention_mask']\n",
        "\n",
        "    all_outputs = []\n",
        "    for i in range(0, len(input_ids), batch_size):\n",
        "        input_batch = input_ids[i:i+batch_size]\n",
        "        mask_batch = attention_mask[i:i+batch_size]\n",
        "\n",
        "        outputs = roberta(input_batch, attention_mask=mask_batch, training=False)\n",
        "        cls_embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "        all_outputs.append(cls_embeddings.numpy())\n",
        "\n",
        "    return np.vstack(all_outputs)\n",
        "\n",
        "# Apply batched extraction\n",
        "train_output = extract_features(train_encodings, batch_size=32)\n",
        "val_output = extract_features(val_encodings, batch_size=32)\n",
        "test_output = extract_features(test_encodings, batch_size=32)\n"
      ],
      "metadata": {
        "id": "A-eOgYn1CCYc",
        "outputId": "2a9149e0-0d77-4225-df1a-9e139403e1ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(train_output.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "r26C10SGcxD3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(train_output.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_output, np.array(train_labels), epochs=5, validation_data=(val_output, np.array(val_labels)))\n"
      ],
      "metadata": {
        "id": "E0G4znqnCGW-",
        "outputId": "0627ddf7-4565-41b4-c1b0-479a6bf81dca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7583 - loss: 0.5256 - val_accuracy: 0.7905 - val_loss: 0.4447\n",
            "Epoch 2/5\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7985 - loss: 0.4362 - val_accuracy: 0.7920 - val_loss: 0.4291\n",
            "Epoch 3/5\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4260 - val_accuracy: 0.7920 - val_loss: 0.4302\n",
            "Epoch 4/5\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.4324 - val_accuracy: 0.7985 - val_loss: 0.4240\n",
            "Epoch 5/5\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.4261 - val_accuracy: 0.7935 - val_loss: 0.4257\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2f188ab210>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Predict on the validation or test set (choose accordingly)\n",
        "predictions = model.predict(val_output)  # For validation, or use test_output for test set\n",
        "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary predictions (0 or 1)\n",
        "\n",
        "# If you want a classification report for the validation set:\n",
        "print(\"Classification Report for Validation Set:\")\n",
        "print(classification_report(np.array(val_labels), predictions))\n",
        "\n",
        "# If you want a classification report for the test set:\n",
        "# print(\"Classification Report for Test Set:\")\n",
        "# print(classification_report(np.array(test_labels), predictions))\n"
      ],
      "metadata": {
        "id": "cZ-JsEb7gROK",
        "outputId": "94795d89-2b2b-43b3-b263-88fadb20f236",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Classification Report for Validation Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.85      0.86      1514\n",
            "           1       0.57      0.62      0.59       486\n",
            "\n",
            "    accuracy                           0.79      2000\n",
            "   macro avg       0.72      0.73      0.73      2000\n",
            "weighted avg       0.80      0.79      0.80      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Recreate clean training/test sets using proper NaN handling\n",
        "train_mask = pd.notna(train_labels)\n",
        "train_output_clean = train_output[train_mask]\n",
        "train_labels_clean = train_labels[train_mask]\n",
        "\n",
        "test_mask = pd.notna(test_labels)\n",
        "test_output_clean = test_output[test_mask]\n",
        "test_labels_clean = test_labels[test_mask]\n",
        "\n",
        "# Now train the Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(train_output_clean, train_labels_clean)\n",
        "preds = rf.predict(test_output_clean)\n",
        "\n",
        "accuracy = accuracy_score(test_labels_clean, preds)\n",
        "print(\"Random Forest Accuracy on Test Set:\", accuracy)\n"
      ],
      "metadata": {
        "id": "21e1eWWNdQnK",
        "outputId": "38fad253-4ba5-4ea0-95b5-af025124b0cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy on Test Set: 0.778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(train_output, train_labels)\n",
        "preds = rf.predict(test_output)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, preds)\n",
        "print(\"Random Forest Accuracy on Test Set:\", accuracy)\n"
      ],
      "metadata": {
        "id": "OFRGzQaMCS3K",
        "outputId": "5c76b42d-9860-4fd0-c57c-cb6686d9539c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8cbad31f9395>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m    361\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     )\n\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0;34m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m         y = check_array(\n\u001b[0m\u001b[1;32m   1398\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Apply on RoBERTa features\n",
        "kmeans = KMeans(n_clusters=5).fit(train_output.numpy())\n",
        "gmm = GaussianMixture(n_components=5).fit(train_output.numpy())\n",
        "\n",
        "# Concatenate cluster assignments\n",
        "import numpy as np\n",
        "\n",
        "train_features = np.concatenate([\n",
        "    train_output.numpy(),\n",
        "    kmeans.predict(train_output.numpy()).reshape(-1, 1),\n",
        "    gmm.predict(train_output.numpy()).reshape(-1, 1)\n",
        "], axis=1)\n",
        "\n",
        "val_features = np.concatenate([\n",
        "    val_output.numpy(),\n",
        "    kmeans.predict(val_output.numpy()).reshape(-1, 1),\n",
        "    gmm.predict(val_output.numpy()).reshape(-1, 1)\n",
        "], axis=1)\n",
        "\n",
        "test_features = np.concatenate([\n",
        "    test_output.numpy(),\n",
        "    kmeans.predict(test_output.numpy()).reshape(-1, 1),\n",
        "    gmm.predict(test_output.numpy()).reshape(-1, 1)\n",
        "], axis=1)\n"
      ],
      "metadata": {
        "id": "pbxH0z81CEUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C9gJOp-3pK6"
      },
      "source": [
        "<h4>Training Curves</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EzL7l_M1HXA"
      },
      "source": [
        "history = history\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhp7jUyPWVf5"
      },
      "source": [
        "# model.load_weights(\"/content/drive/MyDrive/OLID Transformer weights/olid_roberta(0.05).003.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ06iVLk6Y4V"
      },
      "source": [
        "# model.save_weights(\"/content/drive/MyDrive/OLID Transformer weights/olid_roberta(0.05).003.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlcmHgY2QL8u"
      },
      "source": [
        "<h4>Test Set Statistics</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlkXuAvTFZ9z"
      },
      "source": [
        "answer = model.predict([test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAh-EgxOS4I1"
      },
      "source": [
        "pred = []\n",
        "sample = df_test_text[\"tweet\"]\n",
        "count = 0\n",
        "for i in range(0,len(X_test)):\n",
        "\n",
        "    num = answer[i]\n",
        "    if(num >= 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred.append(num)\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqVOLWrFkhnv"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=pred)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeT_iT6HvKF2"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YRvE7emtL9M"
      },
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.set(font_scale=1.75)\n",
        "sns.heatmap(con_mat, annot=True,cmap=plt.cm.viridis,fmt='d', xticklabels=[\"Offensive\",\"Not Offensive\"], yticklabels=[\"Offensive\",\"Not Offensive\"],annot_kws={\"size\": 15})\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jj5ISVyu6Mc"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hznYcG3LtVhx"
      },
      "source": [
        "f1_score(Y_test, pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi9Q-xbecQRM"
      },
      "source": [
        "print(classification_report(Y_test, pred, target_names=[\"offensive\", \"not offensive\"], digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVY5iNvkS5aB"
      },
      "source": [
        "<h3>Train set analysis</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nudw40bYS5Co"
      },
      "source": [
        "answer_train = model.predict([cluster_encodings[\"input_ids\"], cluster_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ8p8hcOTIoE"
      },
      "source": [
        "pred = []\n",
        "sample = original\n",
        "count = 0\n",
        "for i in range(0,len(Y)):\n",
        "\n",
        "    num = answer_train[i]\n",
        "    lol = num\n",
        "    if(num > 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred.append(num)\n",
        "    if(num != Y[i] and Y[i] == 0 and lol >=0.8):\n",
        "        print(answer_train[i])\n",
        "        print(\"Original label: \",labels[i])\n",
        "        print(\"Without pre-processing: \",sample[i])\n",
        "        print(\"With pre-processing: \",X[i])\n",
        "        lol = \"\"\n",
        "        count += 1\n",
        "\n",
        "        if(num == 0):\n",
        "            lol = \"Offensive\"\n",
        "        if(num == 1):\n",
        "            lol = \"Not Offensive\"\n",
        "        print(\"Predicted: \" + lol)\n",
        "        print()\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDHYC0jVktN0"
      },
      "source": [
        "<h3>Training examination</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_JXxlJUIE4I"
      },
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx8jYvYCng6n"
      },
      "source": [
        "# 3 neuron output\n",
        "model.layers[-6].name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJS7gXgJFCCa"
      },
      "source": [
        "cluster_dense_3 = keras.Model(inputs=model.input, outputs=model.layers[-6].output)\n",
        "with strategy.scope():\n",
        "    cluster_3 = cluster_dense_3.predict([cluster_encodings[\"input_ids\"], cluster_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn_QbPYsk9es"
      },
      "source": [
        "pred_train = []\n",
        "temp = 0\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "\n",
        "    num = answer_train[i]\n",
        "\n",
        "    if(num >= 0.5):\n",
        "      num = 1\n",
        "    else:\n",
        "      num = 0\n",
        "    pred_train.append(num)\n",
        "\n",
        "print(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeHnrAsbpq0b"
      },
      "source": [
        "flag = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "    count = count + 1\n",
        "    x_.append(cluster_3[i][1])\n",
        "    y_.append(cluster_3[i][0])\n",
        "    z_.append(cluster_3[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag.append(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aodbtdXNvHhz"
      },
      "source": [
        "Counter(flag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5W6RP9YlCnx"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y, predictions=pred_train)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xr1InDUIS7_"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(flag)):\n",
        "    if flag[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if flag[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if flag[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'x':x_, 'y':y_, 'z':z_, 'Labels':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='x', y='y', z='z', color='Labels')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 0.7,\n",
        "        'colorscale' : 'Oryel',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 750, height = 500)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WF_gbDoZ5Kd"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(flag)):\n",
        "    if pred_train[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if pred_train[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'X':x_, 'Y':y_, 'Z':z_, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='X', y='Y', z='Z', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'rainbow',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvADyeWtkyCa"
      },
      "source": [
        "<h3>Traning examination end</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPUPHuPieZk7"
      },
      "source": [
        "<h1>CLUSTERING</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCoFfK-90oxq"
      },
      "source": [
        "<h3>RoBERTa PLM layer</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZTddCJb0oJD"
      },
      "source": [
        "model.layers[-8].name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk32a2tk0oFC"
      },
      "source": [
        "cluster_bert = keras.Model(inputs=model.input, outputs=model.layers[-8].output)\n",
        "with strategy.scope():\n",
        "    cl_bert = cluster_bert.predict([cluster_encodings[\"input_ids\"], cluster_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r7-V0NqLGqd"
      },
      "source": [
        "len(cl_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVtIKDOf0oBM"
      },
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "    count = count + 1\n",
        "    x_bert.append(cl_bert[i][0])\n",
        "    y_bert.append(cl_bert[i][1])\n",
        "    z_bert.append(cl_bert[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_bert.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f3W0qLE5UlG"
      },
      "source": [
        "<p>k-means PLM layer</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgg7vxiCfX9C"
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDh5fAcH0n9H"
      },
      "source": [
        "kmeans_bert = KMeans(n_clusters=3, random_state=44).fit(cl_bert)\n",
        "y_kmeans_bert = kmeans_bert.predict(cl_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-RuV1hD0n4w"
      },
      "source": [
        "Counter(y_kmeans_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB90wC8s0n0Y"
      },
      "source": [
        "Counter(flag_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n1QV3RZ0nvi"
      },
      "source": [
        "# 1 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_bert)):\n",
        "      if flag_bert[i] == 2 and y_kmeans_bert[i] == 2:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkPj1SQh2xwF"
      },
      "source": [
        "for i in range(0,len(flag_bert)):\n",
        "    if(y_kmeans_bert[i] == 0):\n",
        "      y_kmeans_bert[i] = 1\n",
        "    elif(y_kmeans_bert[i] == 1):\n",
        "      y_kmeans_bert[i] = 0\n",
        "    else:\n",
        "      y_kmeans_bert[i] = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veXnzAlUMw7R"
      },
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(Y)):\n",
        "    count = count + 1\n",
        "    x_bert.append(cl_bert[i][0])\n",
        "    y_bert.append(cl_bert[i][1])\n",
        "    z_bert.append(cl_bert[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_bert.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yshzveBsM4Fm"
      },
      "source": [
        "Counter(flag_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUCI6rBn2xka"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_bert, predictions=y_kmeans_bert)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctpCXXhOo8Cf"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_bert, y_kmeans_bert, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCwmwVNe2xVm"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-88zP4sK2xHi"
      },
      "source": [
        "centers_bert = kmeans_bert.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq0TowJm0nex"
      },
      "source": [
        "svns_off = []\n",
        "for i in range(0,len(Y)):\n",
        "    off = cosine(cl_bert[i], centers_bert[1])/2\n",
        "    svns_off.append(1-off)\n",
        "print(len(svns_off))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRWKQ8RI4Ral"
      },
      "source": [
        "svns_noff = []\n",
        "for i in range(0,len(Y)):\n",
        "    noff = cosine(cl_bert[i], centers_bert[0])/2\n",
        "    svns_noff.append(1-noff)\n",
        "print(len(svns_noff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKo_zWN74RWB"
      },
      "source": [
        "svns_neu = []\n",
        "for i in range(0,len(Y)):\n",
        "    neu = cosine(cl_bert[i], centers_bert[2])/2\n",
        "    svns_neu.append(1-neu)\n",
        "print(len(svns_neu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xakK3QUgNM8G"
      },
      "source": [
        "<h5>k-means PLM plot</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6gKpMTzZYLu"
      },
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgdXokQMXnFF"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if y_kmeans_bert[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_bert[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_bert[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':svns_off, 'SVNS Not Offensive':svns_noff, 'SVNS Neutral':svns_neu, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    },\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9vtWwk8bYDr"
      },
      "source": [
        "pred_krobert = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    if(svns_off[i] > svns_noff[i]):\n",
        "        pred_krobert.append(0)\n",
        "    else:\n",
        "        pred_krobert.append(1)\n",
        "print(classification_report(Y_test, pred_krobert, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh3S5IKEcoQu"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=pred_krobert)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkQoSZi6exAc"
      },
      "source": [
        "<p> GMM model PLM layer</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ty06IQHewe7"
      },
      "source": [
        "from sklearn.mixture import GaussianMixture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4PkC0bPfAB9"
      },
      "source": [
        "gmm_bert = GaussianMixture(n_components=3, random_state = 44).fit(cl_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r87Jsg3oe_UH"
      },
      "source": [
        "mean_bert = gmm_bert.means_\n",
        "cov_bert = gmm_bert.covariances_\n",
        "print(np.shape(mean_bert))\n",
        "print(np.shape(cov_bert))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KakHZ0KYe_QM"
      },
      "source": [
        "labels_bert = gmm_bert.predict(cl_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWqCpdnbKLPt"
      },
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_bert.append(cl_bert[i][0])\n",
        "    y_bert.append(cl_bert[i][1])\n",
        "    z_bert.append(cl_bert[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_bert.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3sXMOuJKefR"
      },
      "source": [
        "Counter(flag_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqRelHjIhQhq"
      },
      "source": [
        "# 1 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_bert)):\n",
        "      if flag_bert[i] == 1 and labels_bert[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvseXiiahQD0"
      },
      "source": [
        "for i in range(0,len(flag_bert)):\n",
        "    if(labels_bert[i] == 0):\n",
        "      labels_bert[i] = 2\n",
        "    elif(labels_bert[i] == 1):\n",
        "      labels_bert[i] = 1\n",
        "    else:\n",
        "      labels_bert[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuN6XZY9Kuys"
      },
      "source": [
        "flag_bert = []\n",
        "count = 0\n",
        "\n",
        "x_bert = []\n",
        "y_bert = []\n",
        "z_bert = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_bert.append(cl_bert[i][0])\n",
        "    y_bert.append(cl_bert[i][1])\n",
        "    z_bert.append(cl_bert[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_bert.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_bert.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_bert.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWmgNWKahjLk"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_bert, predictions=labels_bert)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3od2lBfD3Z41"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_bert, labels_bert, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ZEaAn-Ftq8"
      },
      "source": [
        "prob_bert = gmm_bert.predict_proba(cl_bert)\n",
        "prob_bert = prob_bert.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8hb9kulJeBH"
      },
      "source": [
        "len(y_kmeans_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq43uk25N8-Y"
      },
      "source": [
        "<h5>GMM PLM Plot</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fITkqpNDaNtR"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if labels_bert[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if labels_bert[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if labels_bert[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':prob_bert[2], 'SVNS Non Offensive':prob_bert[1], 'SVNS Neutral':prob_bert[0], 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Non Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1.8,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant', 'font_size':18}, font_size=15, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpYTb160z1N4"
      },
      "source": [
        "<h3>Dense 3 layer</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsnmLYS8IKwY"
      },
      "source": [
        "from sklearn.preprocessing import normalize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gdI2YnUypsL"
      },
      "source": [
        "cl_norm = normalize(cluster_3, norm='l2', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2leCxqUczL9r"
      },
      "source": [
        "flag_3 = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_.append(cl_norm[i][0])\n",
        "    y_.append(cl_norm[i][1])\n",
        "    z_.append(cl_norm[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_3.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_3.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_3.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-RLUrFm6pFu"
      },
      "source": [
        "<p>k-means Dense 3</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF5bqOYoM9nb"
      },
      "source": [
        "kmeans_3 = KMeans(n_clusters=3, random_state=44).fit(cl_norm)\n",
        "y_kmeans_3 = kmeans_3.predict(cl_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42ugjvzrPOhp"
      },
      "source": [
        "Counter(y_kmeans_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGNkI4XGSJeq"
      },
      "source": [
        "Counter(flag_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3QrGYwJPXkh"
      },
      "source": [
        "# 1 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_3)):\n",
        "      if flag_3[i] == 0 and y_kmeans_3[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq2TyIP3PYcM"
      },
      "source": [
        "for i in range(0,len(flag_3)):\n",
        "    if(y_kmeans_3[i] == 0):\n",
        "      y_kmeans_3[i] = 2\n",
        "    elif(y_kmeans_3[i] == 1):\n",
        "      y_kmeans_3[i] = 1\n",
        "    else:\n",
        "      y_kmeans_3[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKSpqPoiPeSG"
      },
      "source": [
        "flag_3 = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_.append(cl_norm[i][2])\n",
        "    y_.append(cl_norm[i][1])\n",
        "    z_.append(cl_norm[i][0])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_3.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_3.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_3.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74XZjQHoow4J"
      },
      "source": [
        "Counter(flag_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YMxovgxcgLU"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_3, predictions=y_kmeans_3)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBGH7CdfRdFl"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_3, y_kmeans_3, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3angcCcHEw5"
      },
      "source": [
        "<p>Transition phase</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66dJKDnVdvPV"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if y_kmeans_3[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_3[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_3[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'X':x_, 'Y':y_, 'Z':z_, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='X', y='Y', z='Z', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVkZLf0wHLol"
      },
      "source": [
        "<p>Original predictions</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiNW3HXMfO-i"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if pred_train[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if pred_train[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'X':x_, 'Y':y_, 'Z':z_, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='X', y='Y', z='Z', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'rainbow',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7d1l_ubROD6"
      },
      "source": [
        "<h4>End of transition capture</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQHolZXSuzK2"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSkLQp_7uy6B"
      },
      "source": [
        "centers_3 = kmeans_3.cluster_centers_\n",
        "print(centers_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USgTEi4ruyos"
      },
      "source": [
        "svns_off = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    off = cosine(cl_norm[i], centers_3[2])/2\n",
        "    svns_off.append(1-off)\n",
        "print(len(svns_off))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Hxo-QLvt1U"
      },
      "source": [
        "svns_noff = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    noff = cosine(cl_norm[i], centers_3[1])/2\n",
        "    svns_noff.append(1-noff)\n",
        "print(len(svns_noff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF5b8CvBvvGo"
      },
      "source": [
        "svns_neu = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    neu = cosine(cl_norm[i], centers_3[0])/2\n",
        "    svns_neu.append(1-neu)\n",
        "print(len(svns_neu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZad5lE_Om-6"
      },
      "source": [
        "<h5>k-means Dense 3 Plot</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDi2Kr1EdDoU"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if y_kmeans_3[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_3[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_3[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':svns_off, 'SVNS Not Offensive':svns_noff, 'SVNS Neutral':svns_neu, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qLv7-NsfgYC"
      },
      "source": [
        "pred_droberta = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    if(svns_off[i] > svns_noff[i]):\n",
        "        pred_droberta.append(0)\n",
        "    else:\n",
        "        pred_droberta.append(1)\n",
        "print(classification_report(Y_test, pred_droberta, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IMG83K9fgOt"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=pred_droberta)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UxQLMFmyX_G"
      },
      "source": [
        "<p> GMM model </p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ3TUE0zyXEr"
      },
      "source": [
        "gmm_3 = GaussianMixture(n_components=3, random_state = 44).fit(cl_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebI2i-bryW7A"
      },
      "source": [
        "mean_norm = gmm_3.means_\n",
        "cov_norm = gmm_3.covariances_\n",
        "print(np.shape(mean_norm))\n",
        "print(np.shape(cov_norm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G4NEJI2yWyI"
      },
      "source": [
        "labels_norm = gmm_3.predict(cl_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--NR_8RmWNdY"
      },
      "source": [
        "flag_3 = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_.append(cl_norm[i][2])\n",
        "    y_.append(cl_norm[i][1])\n",
        "    z_.append(cl_norm[i][0])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_3.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_3.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_3.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP-hLHbbSa8R"
      },
      "source": [
        "Counter(labels_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFJc8jcvWRuc"
      },
      "source": [
        "Counter(flag_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVx299gsyWqC"
      },
      "source": [
        "# 1 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_3)):\n",
        "      if flag_3[i] == 0 and labels_norm[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwj7FBuSzEGw"
      },
      "source": [
        "for i in range(0,len(flag_3)):\n",
        "    if(labels_norm[i] == 0):\n",
        "      labels_norm[i] = 2\n",
        "    elif(labels_norm[i] == 1):\n",
        "      labels_norm[i] = 1\n",
        "    else:\n",
        "      labels_norm[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPH-CLYbWtmD"
      },
      "source": [
        "flag_3 = []\n",
        "count = 0\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "z_ = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_.append(cl_norm[i][2])\n",
        "    y_.append(cl_norm[i][1])\n",
        "    z_.append(cl_norm[i][0])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_3.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_3.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_3.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STLy6RirzECt"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_3, predictions=labels_norm)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K04A25tK40Y8"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_3, labels_norm, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzerzBvA5yh0"
      },
      "source": [
        "prob_norm = gmm_3.predict_proba(cl_norm)\n",
        "prob_norm = prob_norm.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PFUDsrmPLb8"
      },
      "source": [
        "<h5> GMM Dense 3 Plot</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ata8zfmjg6lj"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if labels_norm[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if labels_norm[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if labels_norm[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':prob_norm[2], 'SVNS Not Offensive':prob_norm[1], 'SVNS Neutral':prob_norm[0], 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1.5,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoSh2HkVM-FR"
      },
      "source": [
        "<h3>Dense 3 layer end</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9KReciSt2OQ"
      },
      "source": [
        "<h3>Batch Norm layer</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy39KUfk4YCu"
      },
      "source": [
        "model.layers[-4].name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T2ar9of0Duo"
      },
      "source": [
        "cluster_32 = keras.Model(inputs=model.input, outputs=model.layers[-4].output)\n",
        "with strategy.scope():\n",
        "    cl_32 = cluster_32.predict([test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge2aGeyg4jqM"
      },
      "source": [
        "flag_32 = []\n",
        "count = 0\n",
        "\n",
        "x_32 = []\n",
        "y_32 = []\n",
        "z_32 = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_32.append(cl_32[i][0])\n",
        "    y_32.append(cl_32[i][1])\n",
        "    z_32.append(cl_32[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_32.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_32.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_32.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5NwadS-7cb0"
      },
      "source": [
        "<p>k-means BatchNorm layer</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nv_fX296vdI"
      },
      "source": [
        "kmeans_32 = KMeans(n_clusters=3, random_state=44).fit(cl_32)\n",
        "y_kmeans_32 = kmeans_32.predict(cl_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlkhMcNKJejg"
      },
      "source": [
        "Counter(y_kmeans_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EakhhsbKfjfX"
      },
      "source": [
        "Counter(flag_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnXxczDPWVlZ"
      },
      "source": [
        "# 2 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 0 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(y_kmeans_32)):\n",
        "      if flag_32[i] == 2 and y_kmeans_32[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yPxtiMV_trW"
      },
      "source": [
        "for i in range(0,len(y_kmeans_32)):\n",
        "    if(y_kmeans_32[i] == 0):\n",
        "      y_kmeans_32[i] = 1\n",
        "    elif(y_kmeans_32[i] == 1):\n",
        "      y_kmeans_32[i] = 2\n",
        "    else:\n",
        "      y_kmeans_32[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Toe6CE1ilYGj"
      },
      "source": [
        "flag_32 = []\n",
        "count = 0\n",
        "\n",
        "x_32 = []\n",
        "y_32 = []\n",
        "z_32 = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_32.append(cl_32[i][0])\n",
        "    y_32.append(cl_32[i][1])\n",
        "    z_32.append(cl_32[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_32.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_32.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_32.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC4X5_bGfAwo"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_32, predictions=y_kmeans_32)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpGwKo4jqQPO"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_32, y_kmeans_32, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBWvBFEyyoF"
      },
      "source": [
        "centers_32 = kmeans_32.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sisL0IvdrTP"
      },
      "source": [
        "svns_off = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    off = cosine(cl_32[i], centers_32[1])/2\n",
        "    svns_off.append(1-off)\n",
        "print(len(svns_off))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqDGo4o8k8Ph"
      },
      "source": [
        "svns_noff = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    noff = cosine(cl_32[i], centers_32[2])/2\n",
        "    svns_noff.append(1-noff)\n",
        "print(len(svns_noff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7abIoiRk8CH"
      },
      "source": [
        "svns_neu = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    neu = cosine(cl_32[i], centers_32[0])/2\n",
        "    svns_neu.append(1-neu)\n",
        "print(len(svns_neu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB0ChY0K7kdm"
      },
      "source": [
        "<p>k-means BatchNorm Plot</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbsHcP9Jkjnf"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if y_kmeans_32[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_32[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if y_kmeans_32[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':svns_off, 'SVNS Not Offensive':svns_noff, 'SVNS Neutral':svns_neu, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buEBbUrOh0jC"
      },
      "source": [
        "pred_BNroberta = []\n",
        "for i in range(0,len(Y_test)):\n",
        "    if(svns_off[i] > svns_neu[i]):\n",
        "        pred_BNroberta.append(0)\n",
        "    else:\n",
        "        pred_BNroberta.append(1)\n",
        "print(classification_report(Y_test, pred_BNroberta, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76_dtLm2h0bZ"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=pred_BNroberta)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2xr2iN58eQe"
      },
      "source": [
        "<p> GMM Model </p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnfQ9GrSm2Hh"
      },
      "source": [
        "gmm_32 = GaussianMixture(n_components=3, random_state = 44).fit(cl_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN1DnstL8hfC"
      },
      "source": [
        "mean_32 = gmm_32.means_\n",
        "cov_32 = gmm_32.covariances_\n",
        "print(np.shape(mean_32))\n",
        "print(np.shape(cov_32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCCf6p2W8hbh"
      },
      "source": [
        "labels_32 = gmm_32.predict(cl_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq5znocnV2VF"
      },
      "source": [
        "flag_32 = []\n",
        "count = 0\n",
        "\n",
        "x_32 = []\n",
        "y_32 = []\n",
        "z_32 = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_32.append(cl_32[i][0])\n",
        "    y_32.append(cl_32[i][1])\n",
        "    z_32.append(cl_32[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.28 and answer_train[i] < 0.8 ):\n",
        "        flag_32.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.28 ):\n",
        "        flag_32.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.8 and answer_train[i] < 1 ):\n",
        "        flag_32.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5AgvLFl-4On"
      },
      "source": [
        "Counter(flag_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A7HVs_P8hX2"
      },
      "source": [
        "# 1 index values are offensive\n",
        "# 0 index values are not offensive\n",
        "# 2 index values are neutral\n",
        "\n",
        "count = 0\n",
        "for i in range(0,len(flag_32)):\n",
        "      if flag_32[i] == 1 and labels_32[i] == 1:\n",
        "        count = count + 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjsJFtnd8hT5"
      },
      "source": [
        "for i in range(0,len(flag_32)):\n",
        "    if(labels_32[i] == 0):\n",
        "      labels_32[i] = 2\n",
        "    elif(labels_32[i] == 1):\n",
        "      labels_32[i] = 1\n",
        "    else:\n",
        "      labels_32[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFMHwFz5YY8Q"
      },
      "source": [
        "flag_32 = []\n",
        "count = 0\n",
        "\n",
        "x_32 = []\n",
        "y_32 = []\n",
        "z_32 = []\n",
        "\n",
        "\n",
        "for i in range(0,len(X)):\n",
        "    count = count + 1\n",
        "    x_32.append(cl_32[i][0])\n",
        "    y_32.append(cl_32[i][1])\n",
        "    z_32.append(cl_32[i][2])\n",
        "\n",
        "    if( answer_train[i] > 0.3 and answer_train[i] < 0.7 ):\n",
        "        flag_32.append(2)\n",
        "\n",
        "    if( answer_train[i] > 0 and answer_train[i] <= 0.3 ):\n",
        "        flag_32.append(0)\n",
        "\n",
        "    if( answer_train[i] >= 0.7 and answer_train[i] < 1 ):\n",
        "        flag_32.append(1)\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CV6mSbW8hP2"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=flag_32, predictions=labels_32)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU2xjTjG5i6o"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(flag_32, labels_32, output_dict=False, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w8LxWjbDpkG"
      },
      "source": [
        "prob_32 = gmm_32.predict_proba(cl_32)\n",
        "prob_32 = prob_32.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mmLnenD72Jo"
      },
      "source": [
        "<p>GMM BatchNorm Plot</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Nfvvi1lTsO"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(y_kmeans_bert)):\n",
        "    if labels_32[i] == 2:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if labels_32[i] == 1:\n",
        "      pred_colour.append(\"Not Offensive\")\n",
        "    if labels_32[i] == 0:\n",
        "      pred_colour.append(\"Offensive\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Offensive':prob_32[2], 'SVNS Not Offensive':prob_32[1], 'SVNS Neutral':prob_32[0], 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Offensive', y='SVNS Not Offensive', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1.5,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'}, font_size=14, scene_aspectmode='cube')\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}